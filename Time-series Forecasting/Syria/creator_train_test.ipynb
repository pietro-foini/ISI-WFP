{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the python path to the folder containing some custom packages.\n",
    "import sys\n",
    "sys.path.insert(0, \"../../packages/\")\n",
    "from LagsCreator.LagsCreator import LagsCreator\n",
    "from NestedCV.NestedCV import NestedCV\n",
    "from TsIP.TsIP import TsIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workspace folder for storing training and test points.\n",
    "dir_data = \"./data_xgboost\"\n",
    "os.makedirs(dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the countries to consider for the creation of training and test points.\n",
    "COUNTRIES = [\"Syria\"]\n",
    "# Define the name of indicator we want to predict.\n",
    "# We have to rename the indicator 'FCG <= 2' to 'FCG' (XGBoost issue).\n",
    "TARGET = \"FCG\"\n",
    "# Define the number of days we want to learn to predict for the target variable.\n",
    "TEST_SIZE = 30\n",
    "# Define the number of total split we want to evaluate using our nested cross validation method.\n",
    "NUMBER_OF_SPLITS = 5\n",
    "# Define the time features we want to create for the input samples.\n",
    "FEATURE_TIMES = [\"Day\", \"Month\", \"Dayofweek\", \"Year\"]\n",
    "# Define the step between points during the creation of samples for training and test.\n",
    "STEP_BETWEEN_POINTS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters.\n",
    "with open(dir_data + \"/global_variables\", \"wb\") as f:\n",
    "    pickle.dump([TARGET, TEST_SIZE, FEATURE_TIMES, COUNTRIES, NUMBER_OF_SPLITS, STEP_BETWEEN_POINTS], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the time-series data of the Syria country.\n",
    "df_syria = pd.read_csv(\"../../Dataset time-series/output_data/Syria/Syria.csv\", header = [0, 1], index_col = 0)\n",
    "df_syria.index.name = \"Datetime\"\n",
    "df_syria.index = pd.to_datetime(df_syria.index)\n",
    "freq = \"D\"\n",
    "df_syria.index.freq = freq\n",
    "df_syria.columns = pd.MultiIndex.from_tuples(map(lambda x: (\"Syria\", x[0], x[1]), df_syria.columns), names = [\"Country\", \"AdminStrata\", \"Indicator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th colspan=\"21\" halign=\"left\">Syria</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdminStrata</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Al-Hasakeh</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Tartous</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indicator</th>\n",
       "      <th>1 Month Anomaly Rainfalls (%)</th>\n",
       "      <th>3 Months Anomaly Rainfalls (%)</th>\n",
       "      <th>Code</th>\n",
       "      <th>Exchange rate</th>\n",
       "      <th>FCG</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>...</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price cereals and tubers</th>\n",
       "      <th>Rainfalls (mm)</th>\n",
       "      <th>Ramadan</th>\n",
       "      <th>rCSI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.491475</td>\n",
       "      <td>40.907354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.959426</td>\n",
       "      <td>36.077933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.491475</td>\n",
       "      <td>40.907354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.959426</td>\n",
       "      <td>36.077933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.491475</td>\n",
       "      <td>40.907354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.959426</td>\n",
       "      <td>36.077933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.491475</td>\n",
       "      <td>40.907354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.959426</td>\n",
       "      <td>36.077933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.491475</td>\n",
       "      <td>40.907354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.959426</td>\n",
       "      <td>36.077933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.1629</td>\n",
       "      <td>70.0</td>\n",
       "      <td>36.491475</td>\n",
       "      <td>40.907354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.959426</td>\n",
       "      <td>36.077933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.57902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.1629</td>\n",
       "      <td>66.0</td>\n",
       "      <td>36.491475</td>\n",
       "      <td>40.907354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.959426</td>\n",
       "      <td>36.077933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.87926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.1629</td>\n",
       "      <td>74.0</td>\n",
       "      <td>36.491475</td>\n",
       "      <td>40.907354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.959426</td>\n",
       "      <td>36.077933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.19883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.1629</td>\n",
       "      <td>75.0</td>\n",
       "      <td>36.491475</td>\n",
       "      <td>40.907354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.959426</td>\n",
       "      <td>36.077933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.19883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-31</th>\n",
       "      <td>100.0</td>\n",
       "      <td>97.501211</td>\n",
       "      <td>57</td>\n",
       "      <td>0.783499</td>\n",
       "      <td>43.1629</td>\n",
       "      <td>75.0</td>\n",
       "      <td>36.491475</td>\n",
       "      <td>40.907354</td>\n",
       "      <td>0.151058</td>\n",
       "      <td>107.347575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.959426</td>\n",
       "      <td>36.077933</td>\n",
       "      <td>0.458634</td>\n",
       "      <td>116.477345</td>\n",
       "      <td>831296</td>\n",
       "      <td>0.560945</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.19883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Country                             Syria                                      \\\n",
       "AdminStrata                    Al-Hasakeh                                       \n",
       "Indicator   1 Month Anomaly Rainfalls (%) 3 Months Anomaly Rainfalls (%) Code   \n",
       "Datetime                                                                        \n",
       "2018-01-01                            NaN                            NaN   57   \n",
       "2018-01-02                            NaN                            NaN   57   \n",
       "2018-01-03                            NaN                            NaN   57   \n",
       "2018-01-04                            NaN                            NaN   57   \n",
       "2018-01-05                            NaN                            NaN   57   \n",
       "...                                   ...                            ...  ...   \n",
       "2020-08-27                            NaN                            NaN   57   \n",
       "2020-08-28                            NaN                            NaN   57   \n",
       "2020-08-29                            NaN                            NaN   57   \n",
       "2020-08-30                            NaN                            NaN   57   \n",
       "2020-08-31                          100.0                      97.501211   57   \n",
       "\n",
       "Country                                                                        \\\n",
       "AdminStrata                                                                     \n",
       "Indicator   Exchange rate      FCG Fatalities        Lat        Lon      NDVI   \n",
       "Datetime                                                                        \n",
       "2018-01-01            NaN      NaN        NaN  36.491475  40.907354       NaN   \n",
       "2018-01-02            NaN      NaN        NaN  36.491475  40.907354       NaN   \n",
       "2018-01-03            NaN      NaN        NaN  36.491475  40.907354       NaN   \n",
       "2018-01-04            NaN      NaN        NaN  36.491475  40.907354       NaN   \n",
       "2018-01-05            NaN      NaN        NaN  36.491475  40.907354       NaN   \n",
       "...                   ...      ...        ...        ...        ...       ...   \n",
       "2020-08-27            NaN  43.1629       70.0  36.491475  40.907354       NaN   \n",
       "2020-08-28            NaN  43.1629       66.0  36.491475  40.907354       NaN   \n",
       "2020-08-29            NaN  43.1629       74.0  36.491475  40.907354       NaN   \n",
       "2020-08-30            NaN  43.1629       75.0  36.491475  40.907354       NaN   \n",
       "2020-08-31       0.783499  43.1629       75.0  36.491475  40.907354  0.151058   \n",
       "\n",
       "Country                   ...                                             \\\n",
       "AdminStrata               ...    Tartous                                   \n",
       "Indicator   NDVI Anomaly  ... Fatalities        Lat        Lon      NDVI   \n",
       "Datetime                  ...                                              \n",
       "2018-01-01           NaN  ...        NaN  34.959426  36.077933       NaN   \n",
       "2018-01-02           NaN  ...        NaN  34.959426  36.077933       NaN   \n",
       "2018-01-03           NaN  ...        NaN  34.959426  36.077933       NaN   \n",
       "2018-01-04           NaN  ...        NaN  34.959426  36.077933       NaN   \n",
       "2018-01-05           NaN  ...        NaN  34.959426  36.077933       NaN   \n",
       "...                  ...  ...        ...        ...        ...       ...   \n",
       "2020-08-27           NaN  ...        0.0  34.959426  36.077933       NaN   \n",
       "2020-08-28           NaN  ...        0.0  34.959426  36.077933       NaN   \n",
       "2020-08-29           NaN  ...        0.0  34.959426  36.077933       NaN   \n",
       "2020-08-30           NaN  ...        0.0  34.959426  36.077933       NaN   \n",
       "2020-08-31    107.347575  ...        0.0  34.959426  36.077933  0.458634   \n",
       "\n",
       "Country                                                                      \\\n",
       "AdminStrata                                                                   \n",
       "Indicator   NDVI Anomaly Population Price cereals and tubers Rainfalls (mm)   \n",
       "Datetime                                                                      \n",
       "2018-01-01           NaN     831296                      NaN            NaN   \n",
       "2018-01-02           NaN     831296                      NaN            NaN   \n",
       "2018-01-03           NaN     831296                      NaN            NaN   \n",
       "2018-01-04           NaN     831296                      NaN            NaN   \n",
       "2018-01-05           NaN     831296                      NaN            NaN   \n",
       "...                  ...        ...                      ...            ...   \n",
       "2020-08-27           NaN     831296                      NaN            NaN   \n",
       "2020-08-28           NaN     831296                      NaN            NaN   \n",
       "2020-08-29           NaN     831296                      NaN            NaN   \n",
       "2020-08-30           NaN     831296                      NaN            NaN   \n",
       "2020-08-31    116.477345     831296                 0.560945          0.247   \n",
       "\n",
       "Country                        \n",
       "AdminStrata                    \n",
       "Indicator   Ramadan      rCSI  \n",
       "Datetime                       \n",
       "2018-01-01      NaN       NaN  \n",
       "2018-01-02      NaN       NaN  \n",
       "2018-01-03      NaN       NaN  \n",
       "2018-01-04      NaN       NaN  \n",
       "2018-01-05      NaN       NaN  \n",
       "...             ...       ...  \n",
       "2020-08-27      0.0  42.57902  \n",
       "2020-08-28      0.0  42.87926  \n",
       "2020-08-29      0.0  40.19883  \n",
       "2020-08-30      0.0  40.19883  \n",
       "2020-08-31      0.0  40.19883  \n",
       "\n",
       "[974 rows x 165 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_syria.copy()\n",
    "# Consider the following dates.\n",
    "df = df.loc[\"2018-01-01\":\"2020-08-31\"]\n",
    "# Select countries.\n",
    "df = df[COUNTRIES]\n",
    "# We have to rename the indicator 'FCG <= 2' to 'FCG' and 'rCSI >= 19' to 'rCSI' (XGBoost issue).\n",
    "df.rename({\"FCG <= 2\": \"FCG\", \"rCSI >= 19\": \"rCSI\"}, axis = 1, level = 2, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time-series.\n",
    "#TsIP(df).interactive_plot_df(title = \"Time-series\", matplotlib = False, style = \"mix\", comparison = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lags dictionary for each indicator.\n",
    "lags_dict = dict()\n",
    "# Define lags for each indicator.\n",
    "lags_dict[\"3 Months Anomaly Rainfalls (%)\"] = np.array([1,2,3]) \n",
    "lags_dict[\"1 Month Anomaly Rainfalls (%)\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Rainfalls (mm)\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Exchange rate\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Price cereals and tubers\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Fatalities\"] = np.array([1,2,3,4]) \n",
    "lags_dict[\"NDVI Anomaly\"] = np.array([1,2,3]) \n",
    "lags_dict[\"NDVI\"] = np.array([1,2,3]) \n",
    "lags_dict[\"FCG\"] = np.arange(1, 16)\n",
    "lags_dict[\"rCSI\"] = np.array([1,2,3,4]) \n",
    "lags_dict[\"Lat\"] = np.array([1])\n",
    "lags_dict[\"Lon\"] = np.array([1])\n",
    "lags_dict[\"Population\"] = np.array([1])\n",
    "lags_dict[\"Code\"] = np.array([1])\n",
    "lags_dict[\"Ramadan\"] = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lags dictionary.\n",
    "with open(dir_data + \"/lags_dict\", \"wb\") as fp:\n",
    "    pickle.dump(lags_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for containing training data.\n",
    "os.makedirs(dir_data + \"/train\")\n",
    "# Create folder for containing test data.\n",
    "os.makedirs(dir_data + \"/test\")\n",
    "for country in COUNTRIES:\n",
    "    provinces = df[country].columns.get_level_values(0).unique()\n",
    "    for province in provinces:\n",
    "        os.makedirs(dir_data + \"/train/%s/%s\" % (country, province)) \n",
    "        os.makedirs(dir_data + \"/test/%s/%s\" % (country, province)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: range of days to predict between 2020-04-01 - 2020-04-30\n",
      "Split 2: range of days to predict between 2020-05-01 - 2020-05-30\n",
      "Split 3: range of days to predict between 2020-06-01 - 2020-06-30\n",
      "Split 4: range of days to predict between 2020-07-01 - 2020-07-30\n",
      "Split 5: range of days to predict between 2020-08-01 - 2020-08-30\n"
     ]
    }
   ],
   "source": [
    "# Create the nested cross validation.\n",
    "cv = NestedCV(NUMBER_OF_SPLITS, TEST_SIZE)\n",
    "# Total nested cross validation.\n",
    "SPLITS = cv.get_splits(df)\n",
    "for split_number, (train, test) in SPLITS.items():\n",
    "    print(\"Split %d: range of days to predict between %s - %s\" % (split_number, str(test.index[0].date()), str(test.index[-1].date())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1. Please wait.\n",
      "Split 2. Please wait.\n",
      "Split 3. Please wait.\n",
      "Split 4. Please wait.\n",
      "Split 5. Please wait.\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "for split_number, (train, test) in SPLITS.items():\n",
    "    print(\"Split %d. Please wait.\" % split_number)\n",
    "    # Define the first multi-sites (countries).\n",
    "    countries = train.columns.get_level_values(0).unique()\n",
    "    for country in countries:\n",
    "        train_country = train[country]\n",
    "        # Define the second multi-sites (provinces).\n",
    "        provinces = train_country.columns.get_level_values(0).unique()\n",
    "        for province in provinces:\n",
    "            creator = LagsCreator(train_country[province], lags_dictionary = lags_dict, target = TARGET, delay = True)\n",
    "            for h in range(TEST_SIZE):\n",
    "                # Training samples.\n",
    "                X_train, y_train, X_test, features = creator.to_supervised(h = h+1, step = STEP_BETWEEN_POINTS, single_step = True, \n",
    "                                                                           return_dataframe = True, feature_time = FEATURE_TIMES, \n",
    "                                                                           dtype = float)\n",
    "                \n",
    "                # Train input and output.\n",
    "                X_train.to_csv(dir_data + \"/train/%s/%s/X_train_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "                y_train.to_csv(dir_data + \"/train/%s/%s/y_train_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "                # Test input.\n",
    "                X_test.to_csv(dir_data + \"/test/%s/%s/X_test_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "\n",
    "print(\"Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
