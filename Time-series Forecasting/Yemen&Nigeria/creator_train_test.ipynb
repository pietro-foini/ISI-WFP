{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the python path to the folder containing some custom packages.\n",
    "import sys\n",
    "sys.path.insert(0, \"../../packages/\")\n",
    "from LagsCreator.LagsCreator import LagsCreator\n",
    "from NestedCV.NestedCV import NestedCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workspace folder for storing training and test points.\n",
    "dir_data = \"./data_xgboost\"\n",
    "os.makedirs(dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the countries to consider for the creation of training and test points.\n",
    "COUNTRIES = [\"Yemen\", \"Nigeria\"]\n",
    "# Define the name of indicator we want to predict.\n",
    "# We have to rename the indicator 'FCG <= 2' to 'FCG' (XGBoost issue).\n",
    "TARGET = \"FCG\"\n",
    "# Define the number of days we want to learn to predict for the target variable.\n",
    "TEST_SIZE = 30\n",
    "# Define the number of total split we want to evaluate using our nested cross validation method.\n",
    "NUMBER_OF_SPLITS = 3\n",
    "# Define the time features we want to create for the input samples.\n",
    "FEATURE_TIMES = [\"Day\", \"Month\", \"Dayofweek\", \"Year\"]\n",
    "# Define the step between points during the creation of samples for training and test.\n",
    "STEP_BETWEEN_POINTS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters.\n",
    "with open(dir_data + \"/global_variables\", \"wb\") as f:\n",
    "    pickle.dump([TARGET, TEST_SIZE, FEATURE_TIMES, COUNTRIES, NUMBER_OF_SPLITS, STEP_BETWEEN_POINTS], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the time-series data of the Yemen country.\n",
    "df_yemen = pd.read_csv(\"../../Dataset time-series/output_data/Yemen/Yemen.csv\", header = [0, 1], index_col = 0)\n",
    "df_yemen.index.name = \"Datetime\"\n",
    "df_yemen.index = pd.to_datetime(df_yemen.index)\n",
    "freq = \"D\"\n",
    "df_yemen.index.freq = freq\n",
    "df_yemen.columns = pd.MultiIndex.from_tuples(map(lambda x: (\"Yemen\", x[0], x[1]), df_yemen.columns), names = [\"Country\", \"AdminStrata\", \"Indicator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yemen.drop(\"Exchange rate\", axis = 1, level = 2, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the time-series data of the Nigeria country.\n",
    "df_nigeria = pd.read_csv(\"../../Dataset time-series/output_data/Nigeria/Nigeria.csv\", header = [0, 1], index_col = 0)\n",
    "df_nigeria.index.name = \"Datetime\"\n",
    "df_nigeria.index = pd.to_datetime(df_nigeria.index)\n",
    "freq = \"D\"\n",
    "df_nigeria.index.freq = freq\n",
    "df_nigeria.columns = pd.MultiIndex.from_tuples(map(lambda x: (\"Nigeria\", x[0], x[1]), df_nigeria.columns), names = [\"Country\", \"AdminStrata\", \"Indicator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Yemen</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Nigeria</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdminStrata</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Abyan</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Yobe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indicator</th>\n",
       "      <th>1 Month Anomaly Rainfalls (%)</th>\n",
       "      <th>3 Months Anomaly Rainfalls (%)</th>\n",
       "      <th>Code</th>\n",
       "      <th>FCG</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>Population</th>\n",
       "      <th>...</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price cereals and tubers</th>\n",
       "      <th>Rainfalls (mm)</th>\n",
       "      <th>Ramadan</th>\n",
       "      <th>rCSI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>615154</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>615154</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>615154</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>615154</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>615154</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>41.90447</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>615154</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.358181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>40.88619</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>615154</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.701167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>41.59444</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>615154</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.985136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>41.90045</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>615154</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.888052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-31</th>\n",
       "      <td>109.395086</td>\n",
       "      <td>168.026904</td>\n",
       "      <td>65</td>\n",
       "      <td>42.76342</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>0.174649</td>\n",
       "      <td>142.414507</td>\n",
       "      <td>615154</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>0.515919</td>\n",
       "      <td>98.959882</td>\n",
       "      <td>4340967</td>\n",
       "      <td>0.478635</td>\n",
       "      <td>81.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.357562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows Ã— 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Country                             Yemen                                      \\\n",
       "AdminStrata                         Abyan                                       \n",
       "Indicator   1 Month Anomaly Rainfalls (%) 3 Months Anomaly Rainfalls (%) Code   \n",
       "Datetime                                                                        \n",
       "2018-01-01                            NaN                            NaN   65   \n",
       "2018-01-02                            NaN                            NaN   65   \n",
       "2018-01-03                            NaN                            NaN   65   \n",
       "2018-01-04                            NaN                            NaN   65   \n",
       "2018-01-05                            NaN                            NaN   65   \n",
       "...                                   ...                            ...  ...   \n",
       "2020-08-27                            NaN                            NaN   65   \n",
       "2020-08-28                            NaN                            NaN   65   \n",
       "2020-08-29                            NaN                            NaN   65   \n",
       "2020-08-30                            NaN                            NaN   65   \n",
       "2020-08-31                     109.395086                     168.026904   65   \n",
       "\n",
       "Country                                                                        \\\n",
       "AdminStrata                                                                     \n",
       "Indicator         FCG Fatalities        Lat        Lon      NDVI NDVI Anomaly   \n",
       "Datetime                                                                        \n",
       "2018-01-01        NaN        NaN  13.704878  46.158142       NaN          NaN   \n",
       "2018-01-02        NaN        NaN  13.704878  46.158142       NaN          NaN   \n",
       "2018-01-03        NaN        NaN  13.704878  46.158142       NaN          NaN   \n",
       "2018-01-04        NaN        NaN  13.704878  46.158142       NaN          NaN   \n",
       "2018-01-05        NaN        NaN  13.704878  46.158142       NaN          NaN   \n",
       "...               ...        ...        ...        ...       ...          ...   \n",
       "2020-08-27   41.90447       48.0  13.704878  46.158142       NaN          NaN   \n",
       "2020-08-28   40.88619       48.0  13.704878  46.158142       NaN          NaN   \n",
       "2020-08-29   41.59444       48.0  13.704878  46.158142       NaN          NaN   \n",
       "2020-08-30   41.90045       48.0  13.704878  46.158142       NaN          NaN   \n",
       "2020-08-31   42.76342       48.0  13.704878  46.158142  0.174649   142.414507   \n",
       "\n",
       "Country                 ...    Nigeria                                 \\\n",
       "AdminStrata             ...       Yobe                                  \n",
       "Indicator   Population  ... Fatalities       Lat        Lon      NDVI   \n",
       "Datetime                ...                                             \n",
       "2018-01-01      615154  ...        NaN  12.29868  11.437066       NaN   \n",
       "2018-01-02      615154  ...        NaN  12.29868  11.437066       NaN   \n",
       "2018-01-03      615154  ...        NaN  12.29868  11.437066       NaN   \n",
       "2018-01-04      615154  ...        NaN  12.29868  11.437066       NaN   \n",
       "2018-01-05      615154  ...        NaN  12.29868  11.437066       NaN   \n",
       "...                ...  ...        ...       ...        ...       ...   \n",
       "2020-08-27      615154  ...        3.0  12.29868  11.437066       NaN   \n",
       "2020-08-28      615154  ...        3.0  12.29868  11.437066       NaN   \n",
       "2020-08-29      615154  ...        3.0  12.29868  11.437066       NaN   \n",
       "2020-08-30      615154  ...        3.0  12.29868  11.437066       NaN   \n",
       "2020-08-31      615154  ...        6.0  12.29868  11.437066  0.515919   \n",
       "\n",
       "Country                                                                      \\\n",
       "AdminStrata                                                                   \n",
       "Indicator   NDVI Anomaly Population Price cereals and tubers Rainfalls (mm)   \n",
       "Datetime                                                                      \n",
       "2018-01-01           NaN    4340967                      NaN            NaN   \n",
       "2018-01-02           NaN    4340967                      NaN            NaN   \n",
       "2018-01-03           NaN    4340967                      NaN            NaN   \n",
       "2018-01-04           NaN    4340967                      NaN            NaN   \n",
       "2018-01-05           NaN    4340967                      NaN            NaN   \n",
       "...                  ...        ...                      ...            ...   \n",
       "2020-08-27           NaN    4340967                      NaN            NaN   \n",
       "2020-08-28           NaN    4340967                      NaN            NaN   \n",
       "2020-08-29           NaN    4340967                      NaN            NaN   \n",
       "2020-08-30           NaN    4340967                      NaN            NaN   \n",
       "2020-08-31     98.959882    4340967                 0.478635         81.125   \n",
       "\n",
       "Country                         \n",
       "AdminStrata                     \n",
       "Indicator   Ramadan       rCSI  \n",
       "Datetime                        \n",
       "2018-01-01      NaN        NaN  \n",
       "2018-01-02      NaN        NaN  \n",
       "2018-01-03      NaN        NaN  \n",
       "2018-01-04      NaN        NaN  \n",
       "2018-01-05      NaN        NaN  \n",
       "...             ...        ...  \n",
       "2020-08-27      0.0  12.358181  \n",
       "2020-08-28      0.0  12.701167  \n",
       "2020-08-29      0.0  12.985136  \n",
       "2020-08-30      0.0  12.888052  \n",
       "2020-08-31      0.0  13.357562  \n",
       "\n",
       "[974 rows x 322 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate data of the two countries by date.\n",
    "df = pd.concat([df_yemen, df_nigeria], axis = 1)\n",
    "# Consider the following dates.\n",
    "df = df.loc[\"2018-01-01\":\"2020-08-31\"]\n",
    "# Select countries.\n",
    "df = df[COUNTRIES]\n",
    "# We have to rename the indicator 'FCG <= 2' to 'FCG' and 'rCSI >= 19' to 'rCSI' (XGBoost issue).\n",
    "df.rename({\"FCG <= 2\": \"FCG\", \"rCSI >= 19\": \"rCSI\"}, axis = 1, level = 2, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lags dictionary for each indicator.\n",
    "lags_dict = dict()\n",
    "# Define lags for each indicator.\n",
    "lags_dict[\"3 Months Anomaly Rainfalls (%)\"] = np.array([1,2,3]) \n",
    "lags_dict[\"1 Month Anomaly Rainfalls (%)\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Rainfalls (mm)\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Price cereals and tubers\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Fatalities\"] = np.array([1,2,3,4]) \n",
    "lags_dict[\"NDVI Anomaly\"] = np.array([1,2,3]) \n",
    "lags_dict[\"NDVI\"] = np.array([1,2,3]) \n",
    "lags_dict[\"FCG\"] = np.arange(1, 15)\n",
    "lags_dict[\"rCSI\"] = np.array([1,2,3,4]) \n",
    "lags_dict[\"Lat\"] = np.array([1])\n",
    "lags_dict[\"Lon\"] = np.array([1])\n",
    "lags_dict[\"Population\"] = np.array([1])\n",
    "lags_dict[\"Code\"] = np.array([1])\n",
    "lags_dict[\"Ramadan\"] = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lags dictionary.\n",
    "with open(dir_data + \"/lags_dict\", \"wb\") as fp:\n",
    "    pickle.dump(lags_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for containing training data.\n",
    "os.makedirs(dir_data + \"/train\")\n",
    "# Create folder for containing test data.\n",
    "os.makedirs(dir_data + \"/test\")\n",
    "for country in COUNTRIES:\n",
    "    provinces = df[country].columns.get_level_values(0).unique()\n",
    "    for province in provinces:\n",
    "        os.makedirs(dir_data + \"/train/%s/%s\" % (country, province)) \n",
    "        os.makedirs(dir_data + \"/test/%s/%s\" % (country, province)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: range of days to predict between 2020-06-01 - 2020-06-30\n",
      "Split 2: range of days to predict between 2020-07-01 - 2020-07-30\n",
      "Split 3: range of days to predict between 2020-08-01 - 2020-08-30\n"
     ]
    }
   ],
   "source": [
    "# Create the nested cross validation.\n",
    "cv = NestedCV(NUMBER_OF_SPLITS, TEST_SIZE)\n",
    "# Total nested cross validation.\n",
    "SPLITS = cv.get_splits(df)\n",
    "for split_number, (train, test) in SPLITS.items():\n",
    "    print(\"Split %d: range of days to predict between %s - %s\" % (split_number, str(test.index[0].date()), str(test.index[-1].date())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1. Please wait.\n",
      "Split 2. Please wait.\n",
      "Split 3. Please wait.\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "for split_number, (train, test) in SPLITS.items():\n",
    "    print(\"Split %d. Please wait.\" % split_number)\n",
    "    # Define the first multi-sites (countries).\n",
    "    countries = train.columns.get_level_values(0).unique()\n",
    "    for country in countries:\n",
    "        train_country = train[country]\n",
    "        # Define the second multi-sites (provinces).\n",
    "        provinces = train_country.columns.get_level_values(0).unique()\n",
    "        for province in provinces:\n",
    "            creator = LagsCreator(train_country[province], lags_dictionary = lags_dict, target = TARGET, delay = True)\n",
    "            for h in range(TEST_SIZE):\n",
    "                # Training samples.\n",
    "                X_train, y_train, X_test, features = creator.to_supervised(h = h+1, step = STEP_BETWEEN_POINTS, single_step = True, \n",
    "                                                                           return_dataframe = True, feature_time = FEATURE_TIMES, \n",
    "                                                                           dtype = float)\n",
    "\n",
    "                # Train input and output.\n",
    "                X_train.to_csv(dir_data + \"/train/%s/%s/X_train_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "                y_train.to_csv(dir_data + \"/train/%s/%s/y_train_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "                # Test input.\n",
    "                X_test.to_csv(dir_data + \"/test/%s/%s/X_test_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "\n",
    "print(\"Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
