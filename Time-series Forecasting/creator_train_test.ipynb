{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the python path to the folder containing some useful custom packages.\n",
    "import sys\n",
    "sys.path.insert(0, \"../packages/\")\n",
    "from LagsCreator.LagsCreator import LagsCreator\n",
    "from NestedCV.NestedCV import NestedCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workspace folder for storing training and test points.\n",
    "dir_data = \"./data_xgboost\"\n",
    "os.makedirs(dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the countries to consider for the creation of training and test points.\n",
    "COUNTRIES = [\"Yemen\", \"Syria\"]\n",
    "# Define the name of indicator we want to predict.\n",
    "TARGET = \"FCS\"\n",
    "# Define the number of days we want to learn to predict for the target variable.\n",
    "TEST_SIZE = 30\n",
    "# Define the number of total split we want to evaluate using our nested cross validation method.\n",
    "NUMBER_OF_SPLITS = 7\n",
    "# Define the time features we want to create for the input samples.\n",
    "FEATURE_TIMES = [\"Day\", \"Month\", \"Dayofweek\", \"Year\"]\n",
    "# Define the step between points during the creation of samples for training and test.\n",
    "STEP_BETWEEN_POINTS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters.\n",
    "with open(dir_data + \"/global_variables\", \"wb\") as f:\n",
    "    pickle.dump([TARGET, TEST_SIZE, FEATURE_TIMES, COUNTRIES, NUMBER_OF_SPLITS, STEP_BETWEEN_POINTS], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the time-series data of the Yemen country.\n",
    "df_yemen = pd.read_csv(\"../Dataset time-series/output_data/Yemen/Yemen.csv\", header = [0, 1], index_col = 0)\n",
    "df_yemen.index.name = \"Datetime\"\n",
    "df_yemen.index = pd.to_datetime(df_yemen.index)\n",
    "freq = \"D\"\n",
    "df_yemen.index.freq = freq\n",
    "df_yemen.columns = pd.MultiIndex.from_tuples(map(lambda x: (\"Yemen\", x[0], x[1]), df_yemen.columns), names = [\"Country\", \"AdminStrata\", \"Indicator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the time-series data of the Syria country.\n",
    "df_syria = pd.read_csv(\"../Dataset time-series/output_data/Syria/Syria.csv\", header = [0, 1], index_col = 0)\n",
    "df_syria.index.name = \"Datetime\"\n",
    "df_syria.index = pd.to_datetime(df_syria.index)\n",
    "freq = \"D\"\n",
    "df_syria.index.freq = freq\n",
    "df_syria.columns = pd.MultiIndex.from_tuples(map(lambda x: (\"Syria\", x[0], x[1]), df_syria.columns), names = [\"Country\", \"AdminStrata\", \"Indicator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Yemen</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Syria</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdminStrata</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Abyan</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Tartous</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indicator</th>\n",
       "      <th>1 Month Anomaly (%) Rainfall</th>\n",
       "      <th>3 Months Anomaly (%) Rainfall</th>\n",
       "      <th>Cereals and tubers</th>\n",
       "      <th>Code</th>\n",
       "      <th>Exchange rate</th>\n",
       "      <th>FCS</th>\n",
       "      <th>Fatality</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>...</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>Oil and fats</th>\n",
       "      <th>Population</th>\n",
       "      <th>Pulses and nuts</th>\n",
       "      <th>Rainfall (mm)</th>\n",
       "      <th>Ramadan</th>\n",
       "      <th>Vegetables and fruits</th>\n",
       "      <th>Wage</th>\n",
       "      <th>rCSI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Country                            Yemen                                \\\n",
       "AdminStrata                        Abyan                                 \n",
       "Indicator   1 Month Anomaly (%) Rainfall 3 Months Anomaly (%) Rainfall   \n",
       "Datetime                                                                 \n",
       "2018-01-01                           NaN                           NaN   \n",
       "2018-01-02                           NaN                           NaN   \n",
       "2018-01-03                           NaN                           NaN   \n",
       "2018-01-04                           NaN                           NaN   \n",
       "2018-01-05                           NaN                           NaN   \n",
       "\n",
       "Country                                                              \\\n",
       "AdminStrata                                                           \n",
       "Indicator   Cereals and tubers Code Exchange rate FCS Fatality Fuel   \n",
       "Datetime                                                              \n",
       "2018-01-01                 NaN   65           NaN NaN      NaN  NaN   \n",
       "2018-01-02                 NaN   65           NaN NaN      NaN  NaN   \n",
       "2018-01-03                 NaN   65           NaN NaN      NaN  NaN   \n",
       "2018-01-04                 NaN   65           NaN NaN      NaN  NaN   \n",
       "2018-01-05                 NaN   65           NaN NaN      NaN  NaN   \n",
       "\n",
       "Country                            ...   Syria                            \\\n",
       "AdminStrata                        ... Tartous                             \n",
       "Indicator          Lat        Lon  ...    NDVI NDVI Anomaly Oil and fats   \n",
       "Datetime                           ...                                     \n",
       "2018-01-01   13.704878  46.158142  ...     NaN          NaN          NaN   \n",
       "2018-01-02   13.704878  46.158142  ...     NaN          NaN          NaN   \n",
       "2018-01-03   13.704878  46.158142  ...     NaN          NaN          NaN   \n",
       "2018-01-04   13.704878  46.158142  ...     NaN          NaN          NaN   \n",
       "2018-01-05   13.704878  46.158142  ...     NaN          NaN          NaN   \n",
       "\n",
       "Country                                                       \\\n",
       "AdminStrata                                                    \n",
       "Indicator   Population Pulses and nuts Rainfall (mm) Ramadan   \n",
       "Datetime                                                       \n",
       "2018-01-01      831296             NaN           NaN     NaN   \n",
       "2018-01-02      831296             NaN           NaN     NaN   \n",
       "2018-01-03      831296             NaN           NaN     NaN   \n",
       "2018-01-04      831296             NaN           NaN     NaN   \n",
       "2018-01-05      831296             NaN           NaN     NaN   \n",
       "\n",
       "Country                                      \n",
       "AdminStrata                                  \n",
       "Indicator   Vegetables and fruits Wage rCSI  \n",
       "Datetime                                     \n",
       "2018-01-01                    NaN  NaN  NaN  \n",
       "2018-01-02                    NaN  NaN  NaN  \n",
       "2018-01-03                    NaN  NaN  NaN  \n",
       "2018-01-04                    NaN  NaN  NaN  \n",
       "2018-01-05                    NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 682 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate data.\n",
    "df = pd.concat([df_yemen, df_syria], axis = 1)\n",
    "# Delete the feature 'Milk and dairy' that it isn't presents for the Yemen country.\n",
    "df = df.drop(\"Milk and dairy\", axis = 1, level = 2)\n",
    "# Consider the following dates.\n",
    "df = df.loc[\"2018-01-01\":\"2020-08-31\"]\n",
    "# Select countries.\n",
    "df = df[COUNTRIES]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lags dictionary for each indicator.\n",
    "lags_dict = dict()\n",
    "# Define lags for each indicator.\n",
    "lags_dict[\"3 Months Anomaly (%) Rainfall\"] = None\n",
    "lags_dict[\"1 Month Anomaly (%) Rainfall\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Rainfall (mm)\"] = np.array([1,2,3,4,5,6]) \n",
    "lags_dict[\"Exchange rate\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Cereals and tubers\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Fuel\"] = None\n",
    "lags_dict[\"Meat, fish and eggs\"] = None\n",
    "lags_dict[\"Miscellaneous food\"] = None\n",
    "lags_dict[\"Oil and fats\"] = None\n",
    "lags_dict[\"Pulses and nuts\"] = None\n",
    "lags_dict[\"Vegetables and fruits\"] = None\n",
    "lags_dict[\"Wage\"] = None\n",
    "lags_dict[\"Fatality\"] = np.arange(1, 61)\n",
    "lags_dict[\"NDVI Anomaly\"] = np.array([1,2,3]) \n",
    "lags_dict[\"NDVI\"] = None\n",
    "lags_dict[\"FCS\"] = np.arange(1, 61)\n",
    "lags_dict[\"rCSI\"] = np.arange(1, 61)\n",
    "lags_dict[\"Lat\"] = np.array([1])\n",
    "lags_dict[\"Lon\"] = np.array([1])\n",
    "lags_dict[\"Population\"] = np.array([1])\n",
    "lags_dict[\"Code\"] = np.array([1])\n",
    "lags_dict[\"Ramadan\"] = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lags dictionary.\n",
    "with open(dir_data + \"/lags_dict\", \"wb\") as fp:\n",
    "    pickle.dump(lags_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for containing training data.\n",
    "os.makedirs(dir_data + \"/train\")\n",
    "# Create folder for containing test data.\n",
    "os.makedirs(dir_data + \"/test\")\n",
    "for country in COUNTRIES:\n",
    "    provinces = df[country].columns.get_level_values(0).unique()\n",
    "    for province in provinces:\n",
    "        os.makedirs(dir_data + \"/train/%s/%s\" % (country, province)) \n",
    "        os.makedirs(dir_data + \"/test/%s/%s\" % (country, province)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: range of days to predict between 2020-02-01 - 2020-03-01\n",
      "Split 2: range of days to predict between 2020-03-01 - 2020-03-30\n",
      "Split 3: range of days to predict between 2020-04-01 - 2020-04-30\n",
      "Split 4: range of days to predict between 2020-05-01 - 2020-05-30\n",
      "Split 5: range of days to predict between 2020-06-01 - 2020-06-30\n",
      "Split 6: range of days to predict between 2020-07-01 - 2020-07-30\n",
      "Split 7: range of days to predict between 2020-08-01 - 2020-08-30\n"
     ]
    }
   ],
   "source": [
    "# Create the nested cross validation.\n",
    "cv = NestedCV(NUMBER_OF_SPLITS, TEST_SIZE)\n",
    "# Total nested cross validation.\n",
    "SPLITS = cv.get_splits(df)\n",
    "for split_number, (train, test) in SPLITS.items():\n",
    "    print(\"Split %d: range of days to predict between %s - %s\" % (split_number, str(test.index[0].date()), str(test.index[-1].date())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1. Please wait.\n",
      "Split 2. Please wait.\n",
      "Split 3. Please wait.\n",
      "Split 4. Please wait.\n",
      "Split 5. Please wait.\n",
      "Split 6. Please wait.\n",
      "Split 7. Please wait.\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "for split_number, (train, test) in SPLITS.items():\n",
    "    print(\"Split %d. Please wait.\" % split_number)\n",
    "    # Define the first multi-sites (countries).\n",
    "    countries = train.columns.get_level_values(0).unique()\n",
    "    for country in countries:\n",
    "        train_country = train[country]\n",
    "        # Define the second multi-sites (provinces).\n",
    "        provinces = train_country.columns.get_level_values(0).unique()\n",
    "        for province in provinces:\n",
    "            creator = LagsCreator(train_country[province], lags_dictionary = lags_dict, target = TARGET, delay = True)\n",
    "            for h in range(TEST_SIZE):\n",
    "                # Training samples.\n",
    "                X_train, y_train, X_test, features = creator.to_supervised(h = h+1, step = STEP_BETWEEN_POINTS, single_step = True, \n",
    "                                                                           return_dataframe = True, feature_time = FEATURE_TIMES, \n",
    "                                                                           dtype = float)\n",
    "\n",
    "                # Train input and output.\n",
    "                X_train.to_csv(dir_data + \"/train/%s/%s/X_train_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "                y_train.to_csv(dir_data + \"/train/%s/%s/y_train_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "                # Test input.\n",
    "                X_test.to_csv(dir_data + \"/test/%s/%s/X_test_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "\n",
    "print(\"Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
