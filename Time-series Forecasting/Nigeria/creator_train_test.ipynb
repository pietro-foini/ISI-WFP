{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the python path to the folder containing some custom packages.\n",
    "import sys\n",
    "sys.path.insert(0, \"../../packages/\")\n",
    "from LagsCreator.LagsCreator import LagsCreator\n",
    "from NestedCV.NestedCV import NestedCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workspace folder for storing training and test points.\n",
    "dir_data = \"./data_xgboost\"\n",
    "os.makedirs(dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the countries to consider for the creation of training and test points.\n",
    "COUNTRIES = [\"Nigeria\"]\n",
    "# Define the name of indicator we want to predict.\n",
    "# We have to rename the indicator 'FCG <= 2' to 'FCG' (XGBoost issue).\n",
    "TARGET = \"FCG\"\n",
    "# Define the number of days we want to learn to predict for the target variable.\n",
    "TEST_SIZE = 30\n",
    "# Define the number of total split we want to evaluate using our nested cross validation method.\n",
    "NUMBER_OF_SPLITS = 3\n",
    "# Define the time features we want to create for the input samples.\n",
    "FEATURE_TIMES = [\"Day\", \"Month\", \"Dayofweek\", \"Year\"]\n",
    "# Define the step between points during the creation of samples for training and test.\n",
    "STEP_BETWEEN_POINTS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters.\n",
    "with open(dir_data + \"/global_variables\", \"wb\") as f:\n",
    "    pickle.dump([TARGET, TEST_SIZE, FEATURE_TIMES, COUNTRIES, NUMBER_OF_SPLITS, STEP_BETWEEN_POINTS], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the time-series data of the Nigeria country.\n",
    "df_nigeria = pd.read_csv(\"../../Dataset time-series/output_data/Nigeria/Nigeria.csv\", header = [0, 1], index_col = 0)\n",
    "df_nigeria.index.name = \"Datetime\"\n",
    "df_nigeria.index = pd.to_datetime(df_nigeria.index)\n",
    "freq = \"D\"\n",
    "df_nigeria.index.freq = freq\n",
    "df_nigeria.columns = pd.MultiIndex.from_tuples(map(lambda x: (\"Nigeria\", x[0], x[1]), df_nigeria.columns), names = [\"Country\", \"AdminStrata\", \"Indicator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th colspan=\"21\" halign=\"left\">Nigeria</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdminStrata</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Adamawa</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Yobe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indicator</th>\n",
       "      <th>1 Month Anomaly Rainfalls (%)</th>\n",
       "      <th>3 Months Anomaly Rainfalls (%)</th>\n",
       "      <th>Code</th>\n",
       "      <th>FCG</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>Population</th>\n",
       "      <th>...</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price cereals and tubers</th>\n",
       "      <th>Rainfalls (mm)</th>\n",
       "      <th>Ramadan</th>\n",
       "      <th>rCSI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.323227</td>\n",
       "      <td>12.400241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4946724</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.323227</td>\n",
       "      <td>12.400241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4946724</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.323227</td>\n",
       "      <td>12.400241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4946724</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.323227</td>\n",
       "      <td>12.400241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4946724</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.323227</td>\n",
       "      <td>12.400241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4946724</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>43.249962</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.323227</td>\n",
       "      <td>12.400241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4946724</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.144478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>41.338927</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.323227</td>\n",
       "      <td>12.400241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4946724</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.943911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>39.494239</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.323227</td>\n",
       "      <td>12.400241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4946724</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.942931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>39.030402</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.323227</td>\n",
       "      <td>12.400241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4946724</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4340967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.829452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-31</th>\n",
       "      <td>61.524847</td>\n",
       "      <td>75.86009</td>\n",
       "      <td>14</td>\n",
       "      <td>39.074789</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.323227</td>\n",
       "      <td>12.400241</td>\n",
       "      <td>0.588015</td>\n",
       "      <td>94.644385</td>\n",
       "      <td>4946724</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.29868</td>\n",
       "      <td>11.437066</td>\n",
       "      <td>0.396574</td>\n",
       "      <td>112.965732</td>\n",
       "      <td>4340967</td>\n",
       "      <td>0.16433</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.450474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1035 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Country                           Nigeria                                      \\\n",
       "AdminStrata                       Adamawa                                       \n",
       "Indicator   1 Month Anomaly Rainfalls (%) 3 Months Anomaly Rainfalls (%) Code   \n",
       "Datetime                                                                        \n",
       "2018-01-01                            NaN                            NaN   14   \n",
       "2018-01-02                            NaN                            NaN   14   \n",
       "2018-01-03                            NaN                            NaN   14   \n",
       "2018-01-04                            NaN                            NaN   14   \n",
       "2018-01-05                            NaN                            NaN   14   \n",
       "...                                   ...                            ...  ...   \n",
       "2020-10-27                            NaN                            NaN   14   \n",
       "2020-10-28                            NaN                            NaN   14   \n",
       "2020-10-29                            NaN                            NaN   14   \n",
       "2020-10-30                            NaN                            NaN   14   \n",
       "2020-10-31                      61.524847                       75.86009   14   \n",
       "\n",
       "Country                                                                        \\\n",
       "AdminStrata                                                                     \n",
       "Indicator          FCG Fatalities       Lat        Lon      NDVI NDVI Anomaly   \n",
       "Datetime                                                                        \n",
       "2018-01-01         NaN        NaN  9.323227  12.400241       NaN          NaN   \n",
       "2018-01-02         NaN        NaN  9.323227  12.400241       NaN          NaN   \n",
       "2018-01-03         NaN        NaN  9.323227  12.400241       NaN          NaN   \n",
       "2018-01-04         NaN        NaN  9.323227  12.400241       NaN          NaN   \n",
       "2018-01-05         NaN        NaN  9.323227  12.400241       NaN          NaN   \n",
       "...                ...        ...       ...        ...       ...          ...   \n",
       "2020-10-27   43.249962        2.0  9.323227  12.400241       NaN          NaN   \n",
       "2020-10-28   41.338927        2.0  9.323227  12.400241       NaN          NaN   \n",
       "2020-10-29   39.494239        2.0  9.323227  12.400241       NaN          NaN   \n",
       "2020-10-30   39.030402        2.0  9.323227  12.400241       NaN          NaN   \n",
       "2020-10-31   39.074789        2.0  9.323227  12.400241  0.588015    94.644385   \n",
       "\n",
       "Country                 ...                                            \\\n",
       "AdminStrata             ...       Yobe                                  \n",
       "Indicator   Population  ... Fatalities       Lat        Lon      NDVI   \n",
       "Datetime                ...                                             \n",
       "2018-01-01     4946724  ...        NaN  12.29868  11.437066       NaN   \n",
       "2018-01-02     4946724  ...        NaN  12.29868  11.437066       NaN   \n",
       "2018-01-03     4946724  ...        NaN  12.29868  11.437066       NaN   \n",
       "2018-01-04     4946724  ...        NaN  12.29868  11.437066       NaN   \n",
       "2018-01-05     4946724  ...        NaN  12.29868  11.437066       NaN   \n",
       "...                ...  ...        ...       ...        ...       ...   \n",
       "2020-10-27     4946724  ...       19.0  12.29868  11.437066       NaN   \n",
       "2020-10-28     4946724  ...       19.0  12.29868  11.437066       NaN   \n",
       "2020-10-29     4946724  ...       19.0  12.29868  11.437066       NaN   \n",
       "2020-10-30     4946724  ...       19.0  12.29868  11.437066       NaN   \n",
       "2020-10-31     4946724  ...       19.0  12.29868  11.437066  0.396574   \n",
       "\n",
       "Country                                                                      \\\n",
       "AdminStrata                                                                   \n",
       "Indicator   NDVI Anomaly Population Price cereals and tubers Rainfalls (mm)   \n",
       "Datetime                                                                      \n",
       "2018-01-01           NaN    4340967                      NaN            NaN   \n",
       "2018-01-02           NaN    4340967                      NaN            NaN   \n",
       "2018-01-03           NaN    4340967                      NaN            NaN   \n",
       "2018-01-04           NaN    4340967                      NaN            NaN   \n",
       "2018-01-05           NaN    4340967                      NaN            NaN   \n",
       "...                  ...        ...                      ...            ...   \n",
       "2020-10-27           NaN    4340967                      NaN            NaN   \n",
       "2020-10-28           NaN    4340967                      NaN            NaN   \n",
       "2020-10-29           NaN    4340967                      NaN            NaN   \n",
       "2020-10-30           NaN    4340967                      NaN            NaN   \n",
       "2020-10-31    112.965732    4340967                  0.16433          0.438   \n",
       "\n",
       "Country                         \n",
       "AdminStrata                     \n",
       "Indicator   Ramadan       rCSI  \n",
       "Datetime                        \n",
       "2018-01-01      NaN        NaN  \n",
       "2018-01-02      NaN        NaN  \n",
       "2018-01-03      NaN        NaN  \n",
       "2018-01-04      NaN        NaN  \n",
       "2018-01-05      NaN        NaN  \n",
       "...             ...        ...  \n",
       "2020-10-27      0.0  43.144478  \n",
       "2020-10-28      0.0  45.943911  \n",
       "2020-10-29      0.0  46.942931  \n",
       "2020-10-30      0.0  47.829452  \n",
       "2020-10-31      0.0  50.450474  \n",
       "\n",
       "[1035 rows x 42 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_nigeria.copy()\n",
    "# Consider the following dates.\n",
    "df = df.loc[\"2018-01-01\":\"2020-10-31\"]\n",
    "# Select countries.\n",
    "df = df[COUNTRIES]\n",
    "# We have to rename the indicator 'FCG <= 2' to 'FCG' and 'rCSI >= 19' to 'rCSI' (XGBoost issue).\n",
    "df.rename({\"FCG <= 2\": \"FCG\", \"rCSI >= 19\": \"rCSI\"}, axis = 1, level = 2, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lags dictionary for each indicator.\n",
    "lags_dict = dict()\n",
    "# Define lags for each indicator.\n",
    "lags_dict[\"3 Months Anomaly Rainfalls (%)\"] = np.array([1,2,3]) \n",
    "lags_dict[\"1 Month Anomaly Rainfalls (%)\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Rainfalls (mm)\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Price cereals and tubers\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Fatalities\"] = np.array([1,2,3,4]) \n",
    "lags_dict[\"NDVI Anomaly\"] = np.array([1,2,3]) \n",
    "lags_dict[\"NDVI\"] = np.array([1,2,3]) \n",
    "lags_dict[\"FCG\"] = np.arange(1, 15)\n",
    "lags_dict[\"rCSI\"] = np.array([1,2,3,4]) \n",
    "lags_dict[\"Lat\"] = np.array([1])\n",
    "lags_dict[\"Lon\"] = np.array([1])\n",
    "lags_dict[\"Population\"] = np.array([1])\n",
    "lags_dict[\"Code\"] = np.array([1])\n",
    "lags_dict[\"Ramadan\"] = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lags dictionary.\n",
    "with open(dir_data + \"/lags_dict\", \"wb\") as fp:\n",
    "    pickle.dump(lags_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for containing training data.\n",
    "os.makedirs(dir_data + \"/train\")\n",
    "# Create folder for containing test data.\n",
    "os.makedirs(dir_data + \"/test\")\n",
    "for country in COUNTRIES:\n",
    "    provinces = df[country].columns.get_level_values(0).unique()\n",
    "    for province in provinces:\n",
    "        os.makedirs(dir_data + \"/train/%s/%s\" % (country, province)) \n",
    "        os.makedirs(dir_data + \"/test/%s/%s\" % (country, province)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: range of days to predict between 2020-08-01 - 2020-08-30\n",
      "Split 2: range of days to predict between 2020-09-01 - 2020-09-30\n",
      "Split 3: range of days to predict between 2020-10-01 - 2020-10-30\n"
     ]
    }
   ],
   "source": [
    "# Create the nested cross validation.\n",
    "cv = NestedCV(NUMBER_OF_SPLITS, TEST_SIZE)\n",
    "# Total nested cross validation.\n",
    "SPLITS = cv.get_splits(df)\n",
    "for split_number, (train, test) in SPLITS.items():\n",
    "    print(\"Split %d: range of days to predict between %s - %s\" % (split_number, str(test.index[0].date()), str(test.index[-1].date())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1. Please wait.\n",
      "Split 2. Please wait.\n",
      "Split 3. Please wait.\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "for split_number, (train, test) in SPLITS.items():\n",
    "    print(\"Split %d. Please wait.\" % split_number)\n",
    "    # Define the first multi-sites (countries).\n",
    "    countries = train.columns.get_level_values(0).unique()\n",
    "    for country in countries:\n",
    "        train_country = train[country]\n",
    "        # Define the second multi-sites (provinces).\n",
    "        provinces = train_country.columns.get_level_values(0).unique()\n",
    "        for province in provinces:\n",
    "            creator = LagsCreator(train_country[province], lags_dictionary = lags_dict, target = TARGET, delay = True)\n",
    "            for h in range(TEST_SIZE):\n",
    "                # Training samples.\n",
    "                X_train, y_train, X_test, features = creator.to_supervised(h = h+1, step = STEP_BETWEEN_POINTS, single_step = True, \n",
    "                                                                           return_dataframe = True, feature_time = FEATURE_TIMES, \n",
    "                                                                           dtype = float)\n",
    "\n",
    "                # Train input and output.\n",
    "                X_train.to_csv(dir_data + \"/train/%s/%s/X_train_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "                y_train.to_csv(dir_data + \"/train/%s/%s/y_train_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "                # Test input.\n",
    "                X_test.to_csv(dir_data + \"/test/%s/%s/X_test_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "\n",
    "print(\"Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
