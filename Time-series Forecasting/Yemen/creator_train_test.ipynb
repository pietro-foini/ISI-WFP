{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the python path to the folder containing some custom packages.\n",
    "import sys\n",
    "sys.path.insert(0, \"../../packages/\")\n",
    "from LagsCreator.LagsCreator import LagsCreator\n",
    "from NestedCV.NestedCV import NestedCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workspace folder for storing training and test points.\n",
    "dir_data = \"./data_xgboost\"\n",
    "os.makedirs(dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the countries to consider for the creation of training and test points.\n",
    "COUNTRIES = [\"Yemen\"]\n",
    "# Define the name of indicator we want to predict.\n",
    "# We have to rename the indicator 'FCG <= 2' to 'FCG'.\n",
    "TARGET = \"FCG\"\n",
    "# Define the number of days we want to learn to predict for the target variable.\n",
    "TEST_SIZE = 30\n",
    "# Define the number of total split we want to evaluate using our nested cross validation method.\n",
    "NUMBER_OF_SPLITS = 7\n",
    "# Define the time features we want to create for the input samples.\n",
    "FEATURE_TIMES = [\"Day\", \"Month\", \"Dayofweek\", \"Year\"]\n",
    "# Define the step between points during the creation of samples for training and test.\n",
    "STEP_BETWEEN_POINTS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters.\n",
    "with open(dir_data + \"/global_variables\", \"wb\") as f:\n",
    "    pickle.dump([TARGET, TEST_SIZE, FEATURE_TIMES, COUNTRIES, NUMBER_OF_SPLITS, STEP_BETWEEN_POINTS], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the time-series data of the Yemen country.\n",
    "df_yemen = pd.read_csv(\"../../Dataset time-series/output_data/Yemen/Yemen.csv\", header = [0, 1], index_col = 0)\n",
    "df_yemen.index.name = \"Datetime\"\n",
    "df_yemen.index = pd.to_datetime(df_yemen.index)\n",
    "freq = \"D\"\n",
    "df_yemen.index.freq = freq\n",
    "df_yemen.columns = pd.MultiIndex.from_tuples(map(lambda x: (\"Yemen\", x[0], x[1]), df_yemen.columns), names = [\"Country\", \"AdminStrata\", \"Indicator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th colspan=\"21\" halign=\"left\">Yemen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdminStrata</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Abyan</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Taizz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indicator</th>\n",
       "      <th>1 Month Anomaly Rainfalls (%)</th>\n",
       "      <th>3 Months Anomaly Rainfalls (%)</th>\n",
       "      <th>Code</th>\n",
       "      <th>Exchange rate</th>\n",
       "      <th>FCG</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>...</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price cereals and tubers</th>\n",
       "      <th>Rainfalls (mm)</th>\n",
       "      <th>Ramadan</th>\n",
       "      <th>rCSI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.416517</td>\n",
       "      <td>43.778161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3065034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.416517</td>\n",
       "      <td>43.778161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3065034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.416517</td>\n",
       "      <td>43.778161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3065034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.416517</td>\n",
       "      <td>43.778161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3065034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.416517</td>\n",
       "      <td>43.778161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3065034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.90447</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13.416517</td>\n",
       "      <td>43.778161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3065034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.41219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.88619</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.416517</td>\n",
       "      <td>43.778161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3065034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.55096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.59444</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.416517</td>\n",
       "      <td>43.778161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3065034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.33595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.90045</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>13.416517</td>\n",
       "      <td>43.778161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3065034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.57882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-31</th>\n",
       "      <td>109.395086</td>\n",
       "      <td>168.026904</td>\n",
       "      <td>65</td>\n",
       "      <td>0.619324</td>\n",
       "      <td>42.76342</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.704878</td>\n",
       "      <td>46.158142</td>\n",
       "      <td>0.174649</td>\n",
       "      <td>142.414507</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>13.416517</td>\n",
       "      <td>43.778161</td>\n",
       "      <td>0.261256</td>\n",
       "      <td>121.185954</td>\n",
       "      <td>3065034</td>\n",
       "      <td>0.461194</td>\n",
       "      <td>15.682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.37728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Country                             Yemen                                      \\\n",
       "AdminStrata                         Abyan                                       \n",
       "Indicator   1 Month Anomaly Rainfalls (%) 3 Months Anomaly Rainfalls (%) Code   \n",
       "Datetime                                                                        \n",
       "2018-01-01                            NaN                            NaN   65   \n",
       "2018-01-02                            NaN                            NaN   65   \n",
       "2018-01-03                            NaN                            NaN   65   \n",
       "2018-01-04                            NaN                            NaN   65   \n",
       "2018-01-05                            NaN                            NaN   65   \n",
       "...                                   ...                            ...  ...   \n",
       "2020-08-27                            NaN                            NaN   65   \n",
       "2020-08-28                            NaN                            NaN   65   \n",
       "2020-08-29                            NaN                            NaN   65   \n",
       "2020-08-30                            NaN                            NaN   65   \n",
       "2020-08-31                     109.395086                     168.026904   65   \n",
       "\n",
       "Country                                                               \\\n",
       "AdminStrata                                                            \n",
       "Indicator   Exchange rate       FCG Fatalities        Lat        Lon   \n",
       "Datetime                                                               \n",
       "2018-01-01            NaN       NaN        NaN  13.704878  46.158142   \n",
       "2018-01-02            NaN       NaN        NaN  13.704878  46.158142   \n",
       "2018-01-03            NaN       NaN        NaN  13.704878  46.158142   \n",
       "2018-01-04            NaN       NaN        NaN  13.704878  46.158142   \n",
       "2018-01-05            NaN       NaN        NaN  13.704878  46.158142   \n",
       "...                   ...       ...        ...        ...        ...   \n",
       "2020-08-27            NaN  41.90447       48.0  13.704878  46.158142   \n",
       "2020-08-28            NaN  40.88619       48.0  13.704878  46.158142   \n",
       "2020-08-29            NaN  41.59444       48.0  13.704878  46.158142   \n",
       "2020-08-30            NaN  41.90045       48.0  13.704878  46.158142   \n",
       "2020-08-31       0.619324  42.76342       48.0  13.704878  46.158142   \n",
       "\n",
       "Country                             ...                                   \\\n",
       "AdminStrata                         ...      Taizz                         \n",
       "Indicator        NDVI NDVI Anomaly  ... Fatalities        Lat        Lon   \n",
       "Datetime                            ...                                    \n",
       "2018-01-01        NaN          NaN  ...        NaN  13.416517  43.778161   \n",
       "2018-01-02        NaN          NaN  ...        NaN  13.416517  43.778161   \n",
       "2018-01-03        NaN          NaN  ...        NaN  13.416517  43.778161   \n",
       "2018-01-04        NaN          NaN  ...        NaN  13.416517  43.778161   \n",
       "2018-01-05        NaN          NaN  ...        NaN  13.416517  43.778161   \n",
       "...               ...          ...  ...        ...        ...        ...   \n",
       "2020-08-27        NaN          NaN  ...       45.0  13.416517  43.778161   \n",
       "2020-08-28        NaN          NaN  ...       35.0  13.416517  43.778161   \n",
       "2020-08-29        NaN          NaN  ...       35.0  13.416517  43.778161   \n",
       "2020-08-30        NaN          NaN  ...       34.0  13.416517  43.778161   \n",
       "2020-08-31   0.174649   142.414507  ...       33.0  13.416517  43.778161   \n",
       "\n",
       "Country                                                                 \\\n",
       "AdminStrata                                                              \n",
       "Indicator        NDVI NDVI Anomaly Population Price cereals and tubers   \n",
       "Datetime                                                                 \n",
       "2018-01-01        NaN          NaN    3065034                      NaN   \n",
       "2018-01-02        NaN          NaN    3065034                      NaN   \n",
       "2018-01-03        NaN          NaN    3065034                      NaN   \n",
       "2018-01-04        NaN          NaN    3065034                      NaN   \n",
       "2018-01-05        NaN          NaN    3065034                      NaN   \n",
       "...               ...          ...        ...                      ...   \n",
       "2020-08-27        NaN          NaN    3065034                      NaN   \n",
       "2020-08-28        NaN          NaN    3065034                      NaN   \n",
       "2020-08-29        NaN          NaN    3065034                      NaN   \n",
       "2020-08-30        NaN          NaN    3065034                      NaN   \n",
       "2020-08-31   0.261256   121.185954    3065034                 0.461194   \n",
       "\n",
       "Country                                       \n",
       "AdminStrata                                   \n",
       "Indicator   Rainfalls (mm) Ramadan      rCSI  \n",
       "Datetime                                      \n",
       "2018-01-01             NaN     NaN       NaN  \n",
       "2018-01-02             NaN     NaN       NaN  \n",
       "2018-01-03             NaN     NaN       NaN  \n",
       "2018-01-04             NaN     NaN       NaN  \n",
       "2018-01-05             NaN     NaN       NaN  \n",
       "...                    ...     ...       ...  \n",
       "2020-08-27             NaN     0.0  51.41219  \n",
       "2020-08-28             NaN     0.0  49.55096  \n",
       "2020-08-29             NaN     0.0  50.33595  \n",
       "2020-08-30             NaN     0.0  50.57882  \n",
       "2020-08-31          15.682     0.0  51.37728  \n",
       "\n",
       "[974 rows x 300 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_yemen.copy()\n",
    "# Consider the following dates.\n",
    "df = df.loc[\"2018-01-01\":\"2020-08-31\"]\n",
    "# Select countries.\n",
    "df = df[COUNTRIES]\n",
    "# We have to rename the indicator 'FCG <= 2' to 'FCG' and 'rCSI >= 19' to 'rCSI' (XGBoost issue).\n",
    "df.rename({\"FCG <= 2\": \"FCG\", \"rCSI >= 19\": \"rCSI\"}, axis = 1, level = 2, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lags dictionary for each indicator.\n",
    "lags_dict = dict()\n",
    "# Define lags for each indicator.\n",
    "lags_dict[\"3 Months Anomaly Rainfalls (%)\"] = np.array([1,2,3]) \n",
    "lags_dict[\"1 Month Anomaly Rainfalls (%)\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Rainfalls (mm)\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Exchange rate\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Price cereals and tubers\"] = np.array([1,2,3]) \n",
    "lags_dict[\"Fatalities\"] = np.array([1,2,3,4]) \n",
    "lags_dict[\"NDVI Anomaly\"] = np.array([1,2,3]) \n",
    "lags_dict[\"NDVI\"] = np.array([1,2,3]) \n",
    "lags_dict[\"FCG\"] = np.arange(1, 15)\n",
    "lags_dict[\"rCSI\"] = np.array([1,2,3,4]) \n",
    "lags_dict[\"Lat\"] = np.array([1])\n",
    "lags_dict[\"Lon\"] = np.array([1])\n",
    "lags_dict[\"Population\"] = np.array([1])\n",
    "lags_dict[\"Code\"] = np.array([1])\n",
    "lags_dict[\"Ramadan\"] = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lags dictionary.\n",
    "with open(dir_data + \"/lags_dict\", \"wb\") as fp:\n",
    "    pickle.dump(lags_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for containing training data.\n",
    "os.makedirs(dir_data + \"/train\")\n",
    "# Create folder for containing test data.\n",
    "os.makedirs(dir_data + \"/test\")\n",
    "for country in COUNTRIES:\n",
    "    provinces = df[country].columns.get_level_values(0).unique()\n",
    "    for province in provinces:\n",
    "        os.makedirs(dir_data + \"/train/%s/%s\" % (country, province)) \n",
    "        os.makedirs(dir_data + \"/test/%s/%s\" % (country, province)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: range of days to predict between 2020-02-01 - 2020-03-01\n",
      "Split 2: range of days to predict between 2020-03-01 - 2020-03-30\n",
      "Split 3: range of days to predict between 2020-04-01 - 2020-04-30\n",
      "Split 4: range of days to predict between 2020-05-01 - 2020-05-30\n",
      "Split 5: range of days to predict between 2020-06-01 - 2020-06-30\n",
      "Split 6: range of days to predict between 2020-07-01 - 2020-07-30\n",
      "Split 7: range of days to predict between 2020-08-01 - 2020-08-30\n"
     ]
    }
   ],
   "source": [
    "# Create the nested cross validation.\n",
    "cv = NestedCV(NUMBER_OF_SPLITS, TEST_SIZE)\n",
    "# Total nested cross validation.\n",
    "SPLITS = cv.get_splits(df)\n",
    "for split_number, (train, test) in SPLITS.items():\n",
    "    print(\"Split %d: range of days to predict between %s - %s\" % (split_number, str(test.index[0].date()), str(test.index[-1].date())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1. Please wait.\n",
      "Split 2. Please wait.\n",
      "Split 3. Please wait.\n",
      "Split 4. Please wait.\n",
      "Split 5. Please wait.\n",
      "Split 6. Please wait.\n",
      "Split 7. Please wait.\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "for split_number, (train, test) in SPLITS.items():\n",
    "    print(\"Split %d. Please wait.\" % split_number)\n",
    "    # Define the first multi-sites (countries).\n",
    "    countries = train.columns.get_level_values(0).unique()\n",
    "    for country in countries:\n",
    "        train_country = train[country]\n",
    "        # Define the second multi-sites (provinces).\n",
    "        provinces = train_country.columns.get_level_values(0).unique()\n",
    "        for province in provinces:\n",
    "            creator = LagsCreator(train_country[province], lags_dictionary = lags_dict, target = TARGET, delay = True)\n",
    "            for h in range(TEST_SIZE):\n",
    "                # Training samples.\n",
    "                X_train, y_train, X_test, features = creator.to_supervised(h = h+1, step = STEP_BETWEEN_POINTS, single_step = True, \n",
    "                                                                           return_dataframe = True, feature_time = FEATURE_TIMES, \n",
    "                                                                           dtype = float)\n",
    "\n",
    "                # Train input and output.\n",
    "                X_train.to_csv(dir_data + \"/train/%s/%s/X_train_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "                y_train.to_csv(dir_data + \"/train/%s/%s/y_train_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "                # Test input.\n",
    "                X_test.to_csv(dir_data + \"/test/%s/%s/X_test_split%d_h%d.csv\" % (country, province, split_number, h+1), index_label = False) \n",
    "\n",
    "print(\"Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
