{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the python path to the folder containing some useful custom packages.\n",
    "import sys\n",
    "sys.path.insert(0, \"../../packages/\")\n",
    "from TsIP.TsIP import TsIP\n",
    "from tools import find_multiple_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA_FOLDER = \"../../Dataset time-series/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset of the training sets.\n",
    "train = pd.read_csv(PATH_TO_DATA_FOLDER + \"train_smooth.csv\", header = [0, 1], index_col = 0)\n",
    "train.index.name = \"Datetime\"\n",
    "train.index = pd.to_datetime(train.index)\n",
    "freq = \"D\"\n",
    "train.index.freq = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset of the test sets.\n",
    "test = pd.read_csv(PATH_TO_DATA_FOLDER + \"test_target.csv\", header = [0, 1], index_col = 0)\n",
    "test.index.name = \"Datetime\"\n",
    "test.index = pd.to_datetime(test.index)\n",
    "freq = \"D\"\n",
    "test.index.freq = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset of the whole time-series of the fcs indicator.\n",
    "target = pd.read_csv(PATH_TO_DATA_FOLDER + \"all_target.csv\", header = [0, 1], index_col = 0)\n",
    "target.index.name = \"Datetime\"\n",
    "target.index = pd.to_datetime(target.index)\n",
    "freq = \"D\"\n",
    "target.index.freq = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 30\n",
    "FREQ = train.index.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Abyan', 'Aden', 'Al Bayda', 'Al Dhale'e', 'Al Hudaydah', 'Al Jawf',\n",
       "       'Al Maharah', 'Al Mahwit', 'Amanat Al Asimah', 'Amran', 'Dhamar',\n",
       "       'Hajjah', 'Ibb', 'Lahj', 'Marib', 'Raymah', 'Sa'ada', 'Sana'a',\n",
       "       'Shabwah', 'Taizz'],\n",
       "      dtype='object', name='AdminStrata')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROVINCES = TRAIN.columns.get_level_values(0).unique()\n",
    "PROVINCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1 Month Anomaly (%) Rainfall', '3 Months Anomaly (%) Rainfall',\n",
       "       'Cereals and tubers', 'Exchange rate (USD/LCU)', 'FCS', 'Fatality',\n",
       "       'Lat', 'Lon', 'NDVI Anomaly', 'Population', 'Rainfall (mm)', 'Ramadan',\n",
       "       'rCSI'],\n",
       "      dtype='object', name='Indicator')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICTORS = TRAIN.columns.get_level_values(1).unique()\n",
    "PREDICTORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1 Month Anomaly (%) Rainfall', '3 Months Anomaly (%) Rainfall',\n",
       "       'Cereals and tubers', 'Exchange rate (USD/LCU)', 'FCS', 'Fatality',\n",
       "       'Lat', 'Lon', 'NDVI Anomaly', 'Population', 'Rainfall (mm)', 'Ramadan',\n",
       "       'rCSI'],\n",
       "      dtype='object', name='Indicator')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags_dict = dict()\n",
    "# Define lags for each indicator.\n",
    "lags_dict[\"3 Months Anomaly (%) Rainfall\"] = 10\n",
    "lags_dict[\"1 Month Anomaly (%) Rainfall\"] = 10\n",
    "lags_dict[\"Cereals and tubers\"] = 10\n",
    "lags_dict[\"Exchange rate (USD/LCU)\"] = 10\n",
    "lags_dict[\"FCS\"] = 10\n",
    "lags_dict[\"Fatality\"] = 10\n",
    "lags_dict[\"NDVI Anomaly\"] = 10\n",
    "lags_dict[\"Rainfall (mm)\"] = 10\n",
    "lags_dict[\"rCSI\"] = 10\n",
    "lags_dict[\"Lat\"] = 0\n",
    "lags_dict[\"Lon\"] = 0\n",
    "lags_dict[\"Population\"] = 0\n",
    "lags_dict[\"Ramadan\"] = 10\n",
    "\n",
    "# N.B. If the lags is set to 0 the feature is consedered as static. If no lags is provided the feature is not considered as predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3 Months Anomaly (%) Rainfall': 10,\n",
       " '1 Month Anomaly (%) Rainfall': 10,\n",
       " 'Cereals and tubers': 10,\n",
       " 'Exchange rate (USD/LCU)': 10,\n",
       " 'FCS': 10,\n",
       " 'Fatality': 10,\n",
       " 'NDVI Anomaly': 10,\n",
       " 'Rainfall (mm)': 10,\n",
       " 'rCSI': 10,\n",
       " 'Lat': 0,\n",
       " 'Lon': 0,\n",
       " 'Population': 0,\n",
       " 'Ramadan': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NORMALIZED_SETS = find_multiple_sets(train)\n",
    "TEST_TARGET_SETS = find_multiple_sets(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lags(group, lags_dict, label, n_out = 1):\n",
    "    adminstrata = group.columns[0][0]\n",
    "    group = group[adminstrata]\n",
    "    columns = list(group.columns)\n",
    "    # Not consider predictors whose are not specified into lags_dict (if exist).\n",
    "    predictors_to_remove = list(set(columns) - set(list(lags_dict.keys())))\n",
    "    group_predictors = group.drop(columns = predictors_to_remove)\n",
    "\n",
    "    # Creation of the feature lags of the selected predictors.\n",
    "    dataframe = list()\n",
    "    for feature, lags in lags_dict.items():\n",
    "        # Dynamic predictor.\n",
    "        if lags != 0:\n",
    "            serie = group_predictors[feature]\n",
    "            cols, names = list(), list()\n",
    "            # Input sequences (t-n, ..., t-1).\n",
    "            for i in range(lags, 0, -1):\n",
    "                cols.append(serie.shift(i))\n",
    "                names += [(\"%s(t-%d)\" % (feature, i))]\n",
    "            # Add to the dataframe the new features lags.\n",
    "            feature_lags = pd.concat(cols, axis = 1)\n",
    "            feature_lags.columns = names\n",
    "            dataframe.append(feature_lags)\n",
    "        # Static predictor.\n",
    "        if lags == 0:\n",
    "            serie = group_predictors[feature]\n",
    "            dataframe.append(serie)\n",
    "            \n",
    "    # Matrix of feature lags.\n",
    "    X = pd.concat(dataframe, axis = 1)\n",
    "    X = X.dropna()\n",
    "    if n_out != 1:\n",
    "        X = X[:-(n_out - 1)]\n",
    "    \n",
    "    # Create labels.\n",
    "    target = group[label]\n",
    "    y = target[max(lags_dict.values()) + n_out - 1:]\n",
    "    y = y.to_frame()\n",
    "    if n_out == 1:\n",
    "        y.columns = [\"%s(t)\" % label]\n",
    "    else:\n",
    "        y.columns = [\"%s(t+%d)\" % (label, n_out)]\n",
    "    \n",
    "    # Create feature time.\n",
    "    to_serie = lambda x, y: pd.Series(x, index = X.index, name = y)\n",
    "    X = pd.concat([X, to_serie(y.index.day, \"Day\"), to_serie(y.index.month, \"Month\"), \n",
    "                   to_serie(y.index.year, \"Year\")], axis = 1)\n",
    "    \n",
    "    # Create x sample test.\n",
    "    dataframe = list()\n",
    "    for feature, lags in lags_dict.items():\n",
    "        # Dynamic predictor.\n",
    "        if lags != 0:\n",
    "            serie = group_predictors[feature]\n",
    "            cols, names = list(), list()\n",
    "            # Input sequences (t-n, ..., t-1).\n",
    "            for i in range(lags, 0, -1):\n",
    "                cols.append(pd.Series(serie[-i]))\n",
    "                names += [(\"%s(t-%d)\" % (feature, i))]\n",
    "            # Add to the dataframe the new features lags.\n",
    "            feature_lags = pd.concat(cols, axis = 1)\n",
    "            feature_lags.columns = names\n",
    "            dataframe.append(feature_lags)\n",
    "        # Static predictor.\n",
    "        if lags == 0:\n",
    "            serie = group_predictors[feature]\n",
    "            dataframe.append(pd.Series(serie[-1], name = feature))\n",
    "            \n",
    "    X_test = pd.concat(dataframe, axis = 1)  \n",
    "    future_step = pd.date_range(group_predictors.index[-1], group_predictors.index[-1] + n_out*FREQ, freq = FREQ)[-1]\n",
    "    X_test = pd.concat([X_test, pd.Series(future_step.day, name = \"Day\"), pd.Series(future_step.month, name = \"Month\"),\n",
    "                        pd.Series(future_step.year, name = \"Year\")], axis = 1)\n",
    "    X_test.index = [adminstrata]\n",
    "\n",
    "    return X, y, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:58:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:58:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:58:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:59:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:59:32] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:59:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:00:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:00:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:00:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:01:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:01:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:02:09] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:02:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:02:54] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:03:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:03:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:03:54] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:04:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:04:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:04:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:05:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:05:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:05:36] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:05:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:06:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:06:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:06:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:06:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:07:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:07:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "FORECASTING = test.copy()\n",
    "for h in range(TEST_SIZE):\n",
    "    X_list, y_list, X_test_list = list(), list(), list()\n",
    "    for train_normalized in TRAIN_NORMALIZED_SETS:\n",
    "        # Create training samples.  \n",
    "        X_test_list_set = list()\n",
    "        for PROVINCE in PROVINCES:\n",
    "            X, y, X_test = create_lags(train_normalized[[PROVINCE]], lags_dict, n_out = h + 1, label = \"FCS\")\n",
    "            X_list.append(X)\n",
    "            y_list.append(y)\n",
    "            X_test_list_set.append(X_test)\n",
    "            \n",
    "        X_test_list.append(pd.concat(X_test_list_set))    \n",
    "\n",
    "    X = pd.concat(X_list)\n",
    "    y = pd.concat(y_list)\n",
    "    \n",
    "    model = xgb.XGBRegressor(n_estimators = 100)   \n",
    "    model.fit(X, y)  \n",
    "    \n",
    "    # Prediction.\n",
    "    for i, test_set in enumerate(TEST_TARGET_SETS):\n",
    "        for PROVINCE in PROVINCES:\n",
    "            x_sample = X_test_list[i].loc[PROVINCE]\n",
    "            x_sample = x_sample.to_frame().transpose()\n",
    "            y_hat = model.predict(x_sample)[0]\n",
    "            FORECASTING[(PROVINCE, \"FCS\")].loc[test_set.index[h]] = y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasting_target_sets = find_multiple_sets(FORECASTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.05582170460428"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Loss.\n",
    "loss = np.mean([mean_squared_error(test_set, forecasting_set) for test_set, forecasting_set in zip(TEST_TARGET_SETS, forecasting_target_sets)])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bb65d4fd2748cc81be9844cc5bd400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Select:', options=('Time-series', 'Missing values'), value='Tiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot time-series.\n",
    "TsIP(FORECASTING, target).interactive_plot_df(title = \"Forecasting\", matplotlib = False, style = \"lines\", comparison = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
