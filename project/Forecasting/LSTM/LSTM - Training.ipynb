{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pietro\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from tqdm.keras import TqdmCallback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the python path to the folder containing some useful custom packages.\n",
    "import sys\n",
    "sys.path.insert(0, \"../../packages/\")\n",
    "from TsIP.TsIP import TsIP\n",
    "from rolling_window import rolling_window\n",
    "from tools import find_multiple_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create workspace.\n",
    "dir = \"./output\"\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "else:\n",
    "    shutil.rmtree(dir)           \n",
    "    os.makedirs(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I provide an implementation of a **LSTM network** capable to forecast the FCS indicator of each province of the Yemen country using as predictors both the endogenous and the exogenous indicators. The idea of this implementation is to put the data of all province into a single 'pot' for training a single network.\n",
    "\n",
    "Assuming for example to use a *direct* forecast approach to predict some future values of the FCS time-series (denote it as $Z$). Define $P = \\{ùê¥ùëèùë¶ùëéùëõ, ùê¥ùëëùëíùëõ, ‚Ä¶, ùëáùëéùëñùëßùëß\\}$  as the ensemble of all the provinces of the Yemen country: each single province $p$ is described by some own time-series (endogenous and exogenous data sources). $\\forall p \\in P$, we have:\n",
    "\n",
    "<img src=\"./images/direct_forecast.gif\" width=\"700\">\n",
    "\n",
    "Each province will get own set of training points $(\\vec{X}^p, \\vec{y}^p)$. All this points are put into a single ‚Äòpot‚Äô that feed a single neural network: \n",
    "\n",
    "<img src=\"./images/single.png\" width=\"400\">\n",
    "\n",
    "Finally, using the trained network, we can predict the test set ($z_{17}, z_{18}, z_{19}, z_{20}$) feeding to the network the input:\n",
    "\n",
    "$z_{12}, z_{13}, z_{14}, z_{15}, z_{16}$\n",
    "\n",
    "$e_{12}, e_{13}, e_{14}, e_{15}, e_{16}$\n",
    "\n",
    "$v_{12}, v_{13}, v_{14}, v_{15}, v_{16}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike other machine learning algorithms, long short-term memory recurrent neural networks (LSTM) are capable of automatically\n",
    "learning features from sequence data, support multiple-variate data, and can output a variable length sequences that can be used for multi-step forecasting. I'm going to build a network based on LSTM layer. LSTM is useful for time-series prediction beacuse it has memory. How? Through the 'state' of the LSTM layer. It could be 'stateless' (stateful = False) or 'stateful' (stateful = True). \n",
    "\n",
    "- **stateless**: in this case, all the states are resetted together after each batch. A batch with 10 sequences would create 10 states, and all 10 states are resetted automatically after it's processed. The next batch with 10 sequences will create 10 new states, which will also be resetted after this batch is processed. So the memory is involved about the various time-steps of each sequence. If all those sequences have length (timesteps) = 7, the practical result of these two batches is: 20 individual sequences, each with length 7. None of the sequences are related. But of course: the weights (not the states) will be unique for the layer, and will represent what the layer has learned from all the sequences. \n",
    "\n",
    "    - A state is: Where am I now inside a sequence? Which time step is it? How is this particular sequence behaving since its beginning up to now?\n",
    "    - A weight is: What do I know about the general behavior of all sequences I've seen so far?\n",
    "    \n",
    "- **stateful**: in this case, there is also the same number of parallel states, but they will simply not be resetted at all. A batch with 10 sequences will create 10 states that will remain as they are at the end of the batch. The next batch with 10 sequences (it's required to be 10, since the first was 10) will reuse the same 10 states that were created before. The practical result is: the 10 sequences in the second batch are just continuing the 10 sequences of the first batch, as if there had been no interruption at all. If each sequence has length (timesteps) = 7, then the actual meaning is: 10 individual sequences, each with length 14. When you see that you reached the total length of the sequences, then you call model.reset_states(), meaning you will not continue the previous sequences anymore, now you will start feeding new sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. I will use the LSTM in 'stateless' mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA_FOLDER = \"../../Dataset time-series/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "train = pd.read_csv(PATH_TO_DATA_FOLDER + \"train_smooth.csv\", header = [0, 1], index_col = 0)\n",
    "train.index.name = \"Datetime\"\n",
    "train.index = pd.to_datetime(train.index)\n",
    "freq = \"D\"\n",
    "train.index.freq = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "test = pd.read_csv(PATH_TO_DATA_FOLDER + \"test_target.csv\", header = [0, 1], index_col = 0)\n",
    "test.index.name = \"Datetime\"\n",
    "test.index = pd.to_datetime(test.index)\n",
    "freq = \"D\"\n",
    "test.index.freq = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "target = pd.read_csv(PATH_TO_DATA_FOLDER + \"all_target.csv\", header = [0, 1], index_col = 0)\n",
    "target.index.name = \"Datetime\"\n",
    "target.index = pd.to_datetime(target.index)\n",
    "freq = \"D\"\n",
    "target.index.freq = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 30\n",
    "FREQ = train.index.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Abyan', 'Aden', 'Al Bayda', 'Al Dhale'e', 'Al Hudaydah', 'Al Jawf',\n",
       "       'Al Maharah', 'Al Mahwit', 'Amanat Al Asimah', 'Amran', 'Dhamar',\n",
       "       'Hajjah', 'Ibb', 'Lahj', 'Marib', 'Raymah', 'Sa'ada', 'Sana'a',\n",
       "       'Shabwah', 'Taizz'],\n",
       "      dtype='object', name='AdminStrata')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROVINCES = TRAIN.columns.get_level_values(0).unique()\n",
    "PROVINCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1 Month Anomaly (%) Rainfall', '3 Months Anomaly (%) Rainfall',\n",
       "       'Cereals and tubers', 'Exchange rate (USD/LCU)', 'FCS', 'Fatality',\n",
       "       'Lat', 'Lon', 'NDVI Anomaly', 'Population', 'Rainfall (mm)', 'Ramadan',\n",
       "       'rCSI'],\n",
       "      dtype='object', name='Indicator')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICTORS = TRAIN.columns.get_level_values(1).unique()\n",
    "PREDICTORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data source transformation\n",
    "\n",
    "I decide to normalize the data among the provinces considering indicator by indicator and considering only the training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global SCALERS\n",
    "\n",
    "MIN = 0\n",
    "MAX = 1\n",
    "SCALERS = dict()\n",
    "def normalization(group, feature_range):\n",
    "    min_, max_ = feature_range\n",
    "    min_group = group.min().min()\n",
    "    max_group = group.max().max()\n",
    "    \n",
    "    # Normalization.\n",
    "    group_std = (group - min_group) / (max_group - min_group)\n",
    "    group_scaled = group_std * (max_ - min_) + min_\n",
    "\n",
    "    # Save the scalers for the various indicators.\n",
    "    SCALERS[group.name] = (min_group, max_group)\n",
    "\n",
    "    return group_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>AdminStrata</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Abyan</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Taizz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indicator</th>\n",
       "      <th>1 Month Anomaly (%) Rainfall</th>\n",
       "      <th>3 Months Anomaly (%) Rainfall</th>\n",
       "      <th>Cereals and tubers</th>\n",
       "      <th>Exchange rate (USD/LCU)</th>\n",
       "      <th>FCS</th>\n",
       "      <th>Fatality</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>Population</th>\n",
       "      <th>...</th>\n",
       "      <th>Exchange rate (USD/LCU)</th>\n",
       "      <th>FCS</th>\n",
       "      <th>Fatality</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>Population</th>\n",
       "      <th>Rainfall (mm)</th>\n",
       "      <th>Ramadan</th>\n",
       "      <th>rCSI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-22</th>\n",
       "      <td>0.215732</td>\n",
       "      <td>0.334810</td>\n",
       "      <td>0.113035</td>\n",
       "      <td>0.097113</td>\n",
       "      <td>0.398652</td>\n",
       "      <td>0.015955</td>\n",
       "      <td>0.204339</td>\n",
       "      <td>0.354998</td>\n",
       "      <td>0.203677</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100691</td>\n",
       "      <td>0.522180</td>\n",
       "      <td>0.124402</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.317287</td>\n",
       "      <td>0.894478</td>\n",
       "      <td>0.430215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-23</th>\n",
       "      <td>0.214827</td>\n",
       "      <td>0.330565</td>\n",
       "      <td>0.118731</td>\n",
       "      <td>0.108255</td>\n",
       "      <td>0.417303</td>\n",
       "      <td>0.014210</td>\n",
       "      <td>0.204339</td>\n",
       "      <td>0.354998</td>\n",
       "      <td>0.201767</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105181</td>\n",
       "      <td>0.506301</td>\n",
       "      <td>0.118615</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.314277</td>\n",
       "      <td>0.894478</td>\n",
       "      <td>0.436639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-24</th>\n",
       "      <td>0.213375</td>\n",
       "      <td>0.325265</td>\n",
       "      <td>0.121727</td>\n",
       "      <td>0.112477</td>\n",
       "      <td>0.423109</td>\n",
       "      <td>0.014238</td>\n",
       "      <td>0.204339</td>\n",
       "      <td>0.354998</td>\n",
       "      <td>0.199870</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109271</td>\n",
       "      <td>0.495034</td>\n",
       "      <td>0.115735</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.311164</td>\n",
       "      <td>0.894478</td>\n",
       "      <td>0.446466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-25</th>\n",
       "      <td>0.211677</td>\n",
       "      <td>0.319646</td>\n",
       "      <td>0.123281</td>\n",
       "      <td>0.113002</td>\n",
       "      <td>0.424826</td>\n",
       "      <td>0.015126</td>\n",
       "      <td>0.204339</td>\n",
       "      <td>0.354998</td>\n",
       "      <td>0.197950</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113148</td>\n",
       "      <td>0.487033</td>\n",
       "      <td>0.115840</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.307901</td>\n",
       "      <td>0.894478</td>\n",
       "      <td>0.458051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-26</th>\n",
       "      <td>0.209939</td>\n",
       "      <td>0.314103</td>\n",
       "      <td>0.124426</td>\n",
       "      <td>0.112481</td>\n",
       "      <td>0.427781</td>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.204339</td>\n",
       "      <td>0.354998</td>\n",
       "      <td>0.195990</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116965</td>\n",
       "      <td>0.481466</td>\n",
       "      <td>0.118860</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.304470</td>\n",
       "      <td>0.894478</td>\n",
       "      <td>0.470108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "AdminStrata                        Abyan                                \\\n",
       "Indicator   1 Month Anomaly (%) Rainfall 3 Months Anomaly (%) Rainfall   \n",
       "Datetime                                                                 \n",
       "2018-08-22                      0.215732                      0.334810   \n",
       "2018-08-23                      0.214827                      0.330565   \n",
       "2018-08-24                      0.213375                      0.325265   \n",
       "2018-08-25                      0.211677                      0.319646   \n",
       "2018-08-26                      0.209939                      0.314103   \n",
       "\n",
       "AdminStrata                                                                 \\\n",
       "Indicator   Cereals and tubers Exchange rate (USD/LCU)       FCS  Fatality   \n",
       "Datetime                                                                     \n",
       "2018-08-22            0.113035                0.097113  0.398652  0.015955   \n",
       "2018-08-23            0.118731                0.108255  0.417303  0.014210   \n",
       "2018-08-24            0.121727                0.112477  0.423109  0.014238   \n",
       "2018-08-25            0.123281                0.113002  0.424826  0.015126   \n",
       "2018-08-26            0.124426                0.112481  0.427781  0.016268   \n",
       "\n",
       "AdminStrata                                              ...  \\\n",
       "Indicator         Lat       Lon NDVI Anomaly Population  ...   \n",
       "Datetime                                                 ...   \n",
       "2018-08-22   0.204339  0.354998     0.203677   0.137715  ...   \n",
       "2018-08-23   0.204339  0.354998     0.201767   0.137715  ...   \n",
       "2018-08-24   0.204339  0.354998     0.199870   0.137715  ...   \n",
       "2018-08-25   0.204339  0.354998     0.197950   0.137715  ...   \n",
       "2018-08-26   0.204339  0.354998     0.195990   0.137715  ...   \n",
       "\n",
       "AdminStrata                   Taizz                                        \\\n",
       "Indicator   Exchange rate (USD/LCU)       FCS  Fatality      Lat      Lon   \n",
       "Datetime                                                                    \n",
       "2018-08-22                 0.100691  0.522180  0.124402  0.13656  0.07253   \n",
       "2018-08-23                 0.105181  0.506301  0.118615  0.13656  0.07253   \n",
       "2018-08-24                 0.109271  0.495034  0.115735  0.13656  0.07253   \n",
       "2018-08-25                 0.113148  0.487033  0.115840  0.13656  0.07253   \n",
       "2018-08-26                 0.116965  0.481466  0.118860  0.13656  0.07253   \n",
       "\n",
       "AdminStrata                                                          \n",
       "Indicator   NDVI Anomaly Population Rainfall (mm) Ramadan      rCSI  \n",
       "Datetime                                                             \n",
       "2018-08-22      0.317287   0.894478      0.430215     0.0  0.522625  \n",
       "2018-08-23      0.314277   0.894478      0.436639     0.0  0.513277  \n",
       "2018-08-24      0.311164   0.894478      0.446466     0.0  0.511028  \n",
       "2018-08-25      0.307901   0.894478      0.458051     0.0  0.511425  \n",
       "2018-08-26      0.304470   0.894478      0.470108     0.0  0.512072  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_NORMALIZED = TRAIN.groupby(axis = 1, level = 1).apply(lambda x: normalization(x, (MIN, MAX)))\n",
    "TRAIN_NORMALIZED.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9335720bdf4a1ca847ab0a8077bd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='AdminStrata', options=('Abyan', 'Aden', 'Al Bayda', \"Al Dhale‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot time-series.\n",
    "TsIP(TRAIN_NORMALIZED).interactive_plot_df(title = \"Training sets\", matplotlib = False, style = \"lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalization(group_scaled, indicator, feature_range, scalers):\n",
    "    min_, max_ = feature_range\n",
    "    min_group, max_group = scalers[indicator]\n",
    "\n",
    "    group_std = (group_scaled - min_) / (max_ - min_)\n",
    "    group = (group_std * (max_group - min_group)) + min_group\n",
    "    \n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert history into inputs X and outputs y.\n",
    "def to_supervised(group, n_input, n_out, target = \"FCS\"):\n",
    "    adminstrata = group.name\n",
    "    freq = group.index.freq\n",
    "    # Delete level regarding the province information.\n",
    "    group.columns = group.columns.droplevel()\n",
    "\n",
    "    serie_to_predict = group[target][n_input:]\n",
    "    serie_to_predict = serie_to_predict.values\n",
    "    group = group[:-n_out]\n",
    "        \n",
    "    n_features = len(group.columns)\n",
    "    group = group.values\n",
    "\n",
    "    # Rolling window over exogenus and endogenous variables.\n",
    "    X = rolling_window(group, n_input, axes = 0)\n",
    "    y = rolling_window(serie_to_predict, n_out)\n",
    "    # Adjust in order to have shape: (n_samples, time-steps, n_features).\n",
    "\n",
    "    X = X[:y.shape[0]].swapaxes(1, 2)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAGS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NORMALIZED_SETS = find_multiple_sets(TRAIN_NORMALIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: X: (8240, 30, 13) y: (8240, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train_list, y_train_list = list(), list()\n",
    "for train_normalized in TRAIN_NORMALIZED_SETS:\n",
    "    # Create training points.\n",
    "    data_train = train_normalized.groupby(axis = 1, level = 0).apply(lambda x: to_supervised(x, LAGS, TEST_SIZE, \"FCS\"))\n",
    "\n",
    "    # (n_provinces, n_samples, time-steps, n_features)\n",
    "    X_train = np.stack([d[0] for d in data_train])\n",
    "    # (n_provinces, n_samples, n_out)\n",
    "    y_train = np.stack([d[1] for d in data_train])\n",
    "\n",
    "    n_features = X_train.shape[3]\n",
    "\n",
    "    # Merge all the provinces. (n_samples, time-steps, n_features)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train) \n",
    "\n",
    "    # Train splits.\n",
    "    X_train_list.append(X_train)\n",
    "    y_train_list.append(y_train)\n",
    "\n",
    "X_train = np.concatenate(X_train_list)\n",
    "y_train = np.concatenate(y_train_list)\n",
    "\n",
    "print(\"Training shape: X:\", X_train.shape, \"y:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(timesteps, features, n_out):      \n",
    "    model = Sequential()\n",
    "\n",
    "    # MODEL.\n",
    "    model.add(LSTM(10, return_sequences = False, batch_input_shape = (None, timesteps, features)))\n",
    "\n",
    "    model.add(Dense(n_out))  \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343cc3cdb0b74826991f826c2e22d462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = network(LAGS, n_features, TEST_SIZE)\n",
    "# Compile model.\n",
    "model.compile(loss = \"mse\", optimizer = \"adam\")\n",
    "# Fit model.\n",
    "print(\"Training the network:\")\n",
    "history = model.fit(X_train, y_train, epochs = 100, batch_size = 32, verbose = 0, shuffle = True, callbacks = [TqdmCallback(verbose = 1)])\n",
    "\n",
    "# Plot result of the training and validation.\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\"], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TARGET_SETS = find_multiple_sets(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECASTING_NORMALIZED = test.copy()\n",
    "# Prediction over the test sets.\n",
    "for train_set, test_set in zip(TRAIN_NORMALIZED_SETS, TEST_TARGET_SETS):\n",
    "    # Create input test sample.\n",
    "    data_test = train_set.groupby(axis = 1, level = 0).apply(lambda group: group.tail(LAGS).values)\n",
    "    # Prediction for each province.\n",
    "    for province in PROVINCES:\n",
    "        X_test = data_test.loc[province]\n",
    "        X_test = np.expand_dims(X_test, 0)\n",
    "        # Prediction.\n",
    "        y_hats = model.predict(X_test, verbose = 0).flatten() \n",
    "        # Add the prediction to the dataframe.\n",
    "        FORECASTING_NORMALIZED[(province, \"FCS\")].loc[test_set.index] = y_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalization.\n",
    "FORECASTING = denormalization(FORECASTING_NORMALIZED, \"FCS\", (MIN, MAX), SCALERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasting_target_sets = find_multiple_sets(FORECASTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.976595359672434"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Loss.\n",
    "loss = np.mean([mean_squared_error(test_set, forecasting_set) for test_set, forecasting_set in zip(TEST_TARGET_SETS, forecasting_target_sets)])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5689984b10fe42dfb7b53278e1ec0757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Select:', options=('Time-series', 'Missing values'), value='Ti‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot time-series.\n",
    "TsIP(FORECASTING, target).interactive_plot_df(title = \"Forecasting\", matplotlib = False, style = \"lines\", comparison = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
