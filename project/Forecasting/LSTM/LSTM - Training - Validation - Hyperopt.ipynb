{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pietro\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from tqdm.keras import TqdmCallback\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import shutil\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the python path to the folder containing some useful custom packages.\n",
    "import sys\n",
    "sys.path.insert(0, \"../../packages/\")\n",
    "from TsIP.TsIP import TsIP\n",
    "from tools import find_multiple_sets\n",
    "from LagsCreator.LagsCreator import LagsCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create workspace.\n",
    "dir = \"./output\"\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "else:\n",
    "    shutil.rmtree(dir)           \n",
    "    os.makedirs(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I provide an implementation of a **LSTM network** capable to forecast the FCS indicator of each province of the Yemen country using as predictors both the endogenous and the exogenous indicators. The idea of this implementation is to put the data of all province into a single 'pot' for training a single network.\n",
    "\n",
    "Assuming for example to use a *direct* forecast approach to predict some future values of the FCS time-series (denote it as $Z$). Define $P = \\{ùê¥ùëèùë¶ùëéùëõ, ùê¥ùëëùëíùëõ, ‚Ä¶, ùëáùëéùëñùëßùëß\\}$  as the ensemble of all the provinces of the Yemen country: each single province $p$ is described by some own time-series (endogenous and exogenous data sources). $\\forall p \\in P$, we have:\n",
    "\n",
    "<img src=\"./images/direct_forecast.gif\" width=\"700\">\n",
    "\n",
    "Each province will get own set of training points $(\\vec{X}^p, \\vec{y}^p)$. All this points are put into a single ‚Äòpot‚Äô that feed a single neural network: \n",
    "\n",
    "<img src=\"./images/single.png\" width=\"400\">\n",
    "\n",
    "Finally, using the trained network, we can predict the test set ($z_{17}, z_{18}, z_{19}, z_{20}$) feeding to the network the input:\n",
    "\n",
    "$z_{12}, z_{13}, z_{14}, z_{15}, z_{16}$\n",
    "\n",
    "$e_{12}, e_{13}, e_{14}, e_{15}, e_{16}$\n",
    "\n",
    "$v_{12}, v_{13}, v_{14}, v_{15}, v_{16}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike other machine learning algorithms, long short-term memory recurrent neural networks (LSTM) are capable of automatically\n",
    "learning features from sequence data, support multiple-variate data, and can output a variable length sequences that can be used for multi-step forecasting. I'm going to build a network based on LSTM layer. LSTM is useful for time-series prediction beacuse it has memory. How? Through the 'state' of the LSTM layer. It could be 'stateless' (stateful = False) or 'stateful' (stateful = True). \n",
    "\n",
    "- **stateless**: in this case, all the states are resetted together after each batch. A batch with 10 sequences would create 10 states, and all 10 states are resetted automatically after it's processed. The next batch with 10 sequences will create 10 new states, which will also be resetted after this batch is processed. So the memory is involved about the various time-steps of each sequence. If all those sequences have length (timesteps) = 7, the practical result of these two batches is: 20 individual sequences, each with length 7. None of the sequences are related. But of course: the weights (not the states) will be unique for the layer, and will represent what the layer has learned from all the sequences. \n",
    "\n",
    "    - A state is: Where am I now inside a sequence? Which time step is it? How is this particular sequence behaving since its beginning up to now?\n",
    "    - A weight is: What do I know about the general behavior of all sequences I've seen so far?\n",
    "    \n",
    "- **stateful**: in this case, there is also the same number of parallel states, but they will simply not be resetted at all. A batch with 10 sequences will create 10 states that will remain as they are at the end of the batch. The next batch with 10 sequences (it's required to be 10, since the first was 10) will reuse the same 10 states that were created before. The practical result is: the 10 sequences in the second batch are just continuing the 10 sequences of the first batch, as if there had been no interruption at all. If each sequence has length (timesteps) = 7, then the actual meaning is: 10 individual sequences, each with length 14. When you see that you reached the total length of the sequences, then you call model.reset_states(), meaning you will not continue the previous sequences anymore, now you will start feeding new sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. I will use the LSTM in 'stateless' mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA_FOLDER = \"../../Dataset time-series/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset of the training sets.\n",
    "train = pd.read_csv(PATH_TO_DATA_FOLDER + \"train_smooth.csv\", header = [0, 1], index_col = 0)\n",
    "train.index.name = \"Datetime\"\n",
    "train.index = pd.to_datetime(train.index)\n",
    "freq = \"D\"\n",
    "train.index.freq = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset of the test sets.\n",
    "test = pd.read_csv(PATH_TO_DATA_FOLDER + \"test_target.csv\", header = [0, 1], index_col = 0)\n",
    "test.index.name = \"Datetime\"\n",
    "test.index = pd.to_datetime(test.index)\n",
    "freq = \"D\"\n",
    "test.index.freq = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset of the whole time-series of the fcs indicator.\n",
    "target = pd.read_csv(PATH_TO_DATA_FOLDER + \"all_target.csv\", header = [0, 1], index_col = 0)\n",
    "target.index.name = \"Datetime\"\n",
    "target.index = pd.to_datetime(target.index)\n",
    "freq = \"D\"\n",
    "target.index.freq = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "TEST_SIZE = 30\n",
    "FREQ = train.index.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Abyan', 'Aden', 'Al Bayda', 'Al Dhale'e', 'Al Hudaydah', 'Al Jawf',\n",
       "       'Al Maharah', 'Al Mahwit', 'Amanat Al Asimah', 'Amran', 'Dhamar',\n",
       "       'Hajjah', 'Ibb', 'Lahj', 'Marib', 'Raymah', 'Sa'ada', 'Sana'a',\n",
       "       'Shabwah', 'Taizz'],\n",
       "      dtype='object', name='AdminStrata')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROVINCES = TRAIN.columns.get_level_values(0).unique()\n",
    "PROVINCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1 Month Anomaly (%) Rainfall', '3 Months Anomaly (%) Rainfall',\n",
       "       'Cereals and tubers', 'Exchange rate (USD/LCU)', 'FCS', 'Fatality',\n",
       "       'Lat', 'Lon', 'NDVI Anomaly', 'Population', 'Rainfall (mm)', 'Ramadan',\n",
       "       'rCSI'],\n",
       "      dtype='object', name='Indicator')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICTORS = TRAIN.columns.get_level_values(1).unique()\n",
    "PREDICTORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data source transformation\n",
    "\n",
    "I decide to normalize the data among the provinces considering indicator by indicator and considering only the training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global SCALERS\n",
    "\n",
    "MIN = 0\n",
    "MAX = 1\n",
    "SCALERS = dict()\n",
    "def normalization(group, feature_range):\n",
    "    min_, max_ = feature_range\n",
    "    min_group = group.min().min()\n",
    "    max_group = group.max().max()\n",
    "    \n",
    "    # Normalization.\n",
    "    group_std = (group - min_group) / (max_group - min_group)\n",
    "    group_scaled = group_std * (max_ - min_) + min_\n",
    "\n",
    "    # Save the scalers for the various indicators.\n",
    "    SCALERS[group.name] = (min_group, max_group)\n",
    "\n",
    "    return group_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>AdminStrata</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Abyan</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Taizz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indicator</th>\n",
       "      <th>1 Month Anomaly (%) Rainfall</th>\n",
       "      <th>3 Months Anomaly (%) Rainfall</th>\n",
       "      <th>Cereals and tubers</th>\n",
       "      <th>Exchange rate (USD/LCU)</th>\n",
       "      <th>FCS</th>\n",
       "      <th>Fatality</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>Population</th>\n",
       "      <th>...</th>\n",
       "      <th>Exchange rate (USD/LCU)</th>\n",
       "      <th>FCS</th>\n",
       "      <th>Fatality</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>NDVI Anomaly</th>\n",
       "      <th>Population</th>\n",
       "      <th>Rainfall (mm)</th>\n",
       "      <th>Ramadan</th>\n",
       "      <th>rCSI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-22</th>\n",
       "      <td>0.215732</td>\n",
       "      <td>0.334810</td>\n",
       "      <td>0.113035</td>\n",
       "      <td>0.097113</td>\n",
       "      <td>0.398652</td>\n",
       "      <td>0.015955</td>\n",
       "      <td>0.204339</td>\n",
       "      <td>0.354998</td>\n",
       "      <td>0.203677</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100691</td>\n",
       "      <td>0.522180</td>\n",
       "      <td>0.124402</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.317287</td>\n",
       "      <td>0.894478</td>\n",
       "      <td>0.430215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-23</th>\n",
       "      <td>0.214827</td>\n",
       "      <td>0.330565</td>\n",
       "      <td>0.118731</td>\n",
       "      <td>0.108255</td>\n",
       "      <td>0.417303</td>\n",
       "      <td>0.014210</td>\n",
       "      <td>0.204339</td>\n",
       "      <td>0.354998</td>\n",
       "      <td>0.201767</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105181</td>\n",
       "      <td>0.506301</td>\n",
       "      <td>0.118615</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.314277</td>\n",
       "      <td>0.894478</td>\n",
       "      <td>0.436639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-24</th>\n",
       "      <td>0.213375</td>\n",
       "      <td>0.325265</td>\n",
       "      <td>0.121727</td>\n",
       "      <td>0.112477</td>\n",
       "      <td>0.423109</td>\n",
       "      <td>0.014238</td>\n",
       "      <td>0.204339</td>\n",
       "      <td>0.354998</td>\n",
       "      <td>0.199870</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109271</td>\n",
       "      <td>0.495034</td>\n",
       "      <td>0.115735</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.311164</td>\n",
       "      <td>0.894478</td>\n",
       "      <td>0.446466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-25</th>\n",
       "      <td>0.211677</td>\n",
       "      <td>0.319646</td>\n",
       "      <td>0.123281</td>\n",
       "      <td>0.113002</td>\n",
       "      <td>0.424826</td>\n",
       "      <td>0.015126</td>\n",
       "      <td>0.204339</td>\n",
       "      <td>0.354998</td>\n",
       "      <td>0.197950</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113148</td>\n",
       "      <td>0.487033</td>\n",
       "      <td>0.115840</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.307901</td>\n",
       "      <td>0.894478</td>\n",
       "      <td>0.458051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-26</th>\n",
       "      <td>0.209939</td>\n",
       "      <td>0.314103</td>\n",
       "      <td>0.124426</td>\n",
       "      <td>0.112481</td>\n",
       "      <td>0.427781</td>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.204339</td>\n",
       "      <td>0.354998</td>\n",
       "      <td>0.195990</td>\n",
       "      <td>0.137715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116965</td>\n",
       "      <td>0.481466</td>\n",
       "      <td>0.118860</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.304470</td>\n",
       "      <td>0.894478</td>\n",
       "      <td>0.470108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "AdminStrata                        Abyan                                \\\n",
       "Indicator   1 Month Anomaly (%) Rainfall 3 Months Anomaly (%) Rainfall   \n",
       "Datetime                                                                 \n",
       "2018-08-22                      0.215732                      0.334810   \n",
       "2018-08-23                      0.214827                      0.330565   \n",
       "2018-08-24                      0.213375                      0.325265   \n",
       "2018-08-25                      0.211677                      0.319646   \n",
       "2018-08-26                      0.209939                      0.314103   \n",
       "\n",
       "AdminStrata                                                                 \\\n",
       "Indicator   Cereals and tubers Exchange rate (USD/LCU)       FCS  Fatality   \n",
       "Datetime                                                                     \n",
       "2018-08-22            0.113035                0.097113  0.398652  0.015955   \n",
       "2018-08-23            0.118731                0.108255  0.417303  0.014210   \n",
       "2018-08-24            0.121727                0.112477  0.423109  0.014238   \n",
       "2018-08-25            0.123281                0.113002  0.424826  0.015126   \n",
       "2018-08-26            0.124426                0.112481  0.427781  0.016268   \n",
       "\n",
       "AdminStrata                                              ...  \\\n",
       "Indicator         Lat       Lon NDVI Anomaly Population  ...   \n",
       "Datetime                                                 ...   \n",
       "2018-08-22   0.204339  0.354998     0.203677   0.137715  ...   \n",
       "2018-08-23   0.204339  0.354998     0.201767   0.137715  ...   \n",
       "2018-08-24   0.204339  0.354998     0.199870   0.137715  ...   \n",
       "2018-08-25   0.204339  0.354998     0.197950   0.137715  ...   \n",
       "2018-08-26   0.204339  0.354998     0.195990   0.137715  ...   \n",
       "\n",
       "AdminStrata                   Taizz                                        \\\n",
       "Indicator   Exchange rate (USD/LCU)       FCS  Fatality      Lat      Lon   \n",
       "Datetime                                                                    \n",
       "2018-08-22                 0.100691  0.522180  0.124402  0.13656  0.07253   \n",
       "2018-08-23                 0.105181  0.506301  0.118615  0.13656  0.07253   \n",
       "2018-08-24                 0.109271  0.495034  0.115735  0.13656  0.07253   \n",
       "2018-08-25                 0.113148  0.487033  0.115840  0.13656  0.07253   \n",
       "2018-08-26                 0.116965  0.481466  0.118860  0.13656  0.07253   \n",
       "\n",
       "AdminStrata                                                          \n",
       "Indicator   NDVI Anomaly Population Rainfall (mm) Ramadan      rCSI  \n",
       "Datetime                                                             \n",
       "2018-08-22      0.317287   0.894478      0.430215     0.0  0.522625  \n",
       "2018-08-23      0.314277   0.894478      0.436639     0.0  0.513277  \n",
       "2018-08-24      0.311164   0.894478      0.446466     0.0  0.511028  \n",
       "2018-08-25      0.307901   0.894478      0.458051     0.0  0.511425  \n",
       "2018-08-26      0.304470   0.894478      0.470108     0.0  0.512072  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_NORMALIZED = TRAIN.groupby(axis = 1, level = 1).apply(lambda x: normalization(x, (MIN, MAX)))\n",
    "TRAIN_NORMALIZED.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca6a07b034f4892b9cc53cfd28091c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='AdminStrata', options=('Abyan', 'Aden', 'Al Bayda', \"Al Dhale‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot time-series.\n",
    "TsIP(TRAIN_NORMALIZED).interactive_plot_df(title = \"Training sets\", matplotlib = False, style = \"lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalization(group_scaled, indicator, feature_range, scalers):\n",
    "    min_, max_ = feature_range\n",
    "    min_group, max_group = scalers[indicator]\n",
    "\n",
    "    group_std = (group_scaled - min_) / (max_ - min_)\n",
    "    group = (group_std * (max_group - min_group)) + min_group\n",
    "    \n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training and test sets.\n",
    "TRAIN_NORMALIZED_SETS = find_multiple_sets(TRAIN_NORMALIZED)\n",
    "TEST_TARGET_SETS = find_multiple_sets(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Validation\n",
    "### Parameters grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the PARAMETERS MODEL to which perform the grid search.\n",
    "space = {\"lags\": hp.randint(\"lags\", 3, 4), \n",
    "         \"batch_size\": hp.randint(\"batch_size\", 128, 129)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(timesteps, features, n_out):      \n",
    "    model = Sequential()\n",
    "\n",
    "    # MODEL.\n",
    "    model.add(LSTM(10, return_sequences = False, batch_input_shape = (None, timesteps, features)))\n",
    "\n",
    "    model.add(Dense(n_out))  \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameters(space):      \n",
    "    #try:\n",
    "    # Define the parameters to grid search.\n",
    "    LAGS = int(space[\"lags\"])\n",
    "    BATCH_SIZE = int(space[\"batch_size\"])\n",
    "    print(\"lags: %d, batch_size: %d\" %(LAGS, BATCH_SIZE))\n",
    "    \n",
    "    lags_dict = dict()\n",
    "    # Define lags for each indicator.\n",
    "    lags_dict[\"3 Months Anomaly (%) Rainfall\"] = LAGS\n",
    "    lags_dict[\"1 Month Anomaly (%) Rainfall\"] = LAGS\n",
    "    lags_dict[\"Cereals and tubers\"] = LAGS\n",
    "    lags_dict[\"Exchange rate (USD/LCU)\"] = LAGS\n",
    "    lags_dict[\"FCS\"] = LAGS\n",
    "    lags_dict[\"Fatality\"] = LAGS\n",
    "    lags_dict[\"NDVI Anomaly\"] = LAGS\n",
    "    lags_dict[\"Rainfall (mm)\"] = LAGS\n",
    "    lags_dict[\"rCSI\"] = LAGS\n",
    "    lags_dict[\"Lat\"] = LAGS\n",
    "    lags_dict[\"Lon\"] = LAGS\n",
    "    lags_dict[\"Population\"] = LAGS\n",
    "    lags_dict[\"Ramadan\"] = LAGS\n",
    "    \n",
    "    X_train_list, y_train_list, X_val_list, y_val_list = list(), list(), list(), list()\n",
    "    # Create training and validation points starting from the training sets.\n",
    "    for train_normalized in TRAIN_NORMALIZED_SETS:\n",
    "        # Create training and validation points.\n",
    "        data = train_normalized.groupby(axis = 1, level = 0).apply(lambda x: LagsCreator(x, lags_dictionary = lags_dict, \n",
    "                                                                                     target = \"FCS\", n_out = TEST_SIZE, \n",
    "                                                                                     single_step = False, h = None, \n",
    "                                                                                     return_dataframe = False, \n",
    "                                                                                     feature_time = False, \n",
    "                                                                                     validation = True))\n",
    "        # TRAINING SAMPLES.\n",
    "        # (n_provinces, n_samples, time-steps, n_features)\n",
    "        X_train = np.stack([d[0] for d in data])\n",
    "        # (n_provinces, n_samples, n_out)\n",
    "        y_train = np.stack([d[1] for d in data])\n",
    "        # VALIDATION SAMPLES.\n",
    "        # (n_provinces, n_samples, time-steps, n_features)\n",
    "        X_val = np.stack([d[2] for d in data])\n",
    "        # (n_provinces, n_samples, n_out)\n",
    "        y_val = np.stack([d[3] for d in data])\n",
    "\n",
    "        # Merge all the provinces. (n_samples, time-steps, n_features)\n",
    "        X_train = np.concatenate(X_train)\n",
    "        X_val = np.concatenate(X_val)\n",
    "        # Merge all the provinces. (n_samples, n_out)\n",
    "        y_train = np.concatenate(y_train) \n",
    "        y_val = np.concatenate(y_val)\n",
    "\n",
    "        # Add all the train and validation splits.\n",
    "        X_train_list.append(X_train)\n",
    "        y_train_list.append(y_train)\n",
    "        X_val_list.append(X_val)\n",
    "        y_val_list.append(y_val)\n",
    "\n",
    "    X_train = np.concatenate(X_train_list)\n",
    "    y_train = np.concatenate(y_train_list)\n",
    "    X_val = np.concatenate(X_val_list)\n",
    "    y_val = np.concatenate(y_val_list)\n",
    "    \n",
    "    N_FEATURES = X_train.shape[2]\n",
    "\n",
    "    print(\"Training shape:\", X_train.shape)\n",
    "    print(\"Validation shape:\", X_val.shape)\n",
    "\n",
    "    # Model.\n",
    "    model = network(LAGS, N_FEATURES, TEST_SIZE)\n",
    "    # Compile model.\n",
    "    model.compile(loss = \"mse\", optimizer = \"adam\")\n",
    "\n",
    "    # Patient early stopping.\n",
    "    es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 30)\n",
    "    # Fit model.\n",
    "    history = model.fit(X_train, y_train, epochs = N_EPOCHS, validation_data = (X_val, y_val), \n",
    "                        batch_size = BATCH_SIZE, verbose = 0, shuffle = True, callbacks = [es, TqdmCallback(verbose = 1)])\n",
    "\n",
    "    # Save the number of epochs at which fit stop due to early stopping.\n",
    "    number_of_epochs_it_ran = len(history.history[\"loss\"])  \n",
    "    train_loss = history.history[\"loss\"][-1]\n",
    "    val_loss = history.history[\"val_loss\"][-1]\n",
    "\n",
    "    # Recursive save results.\n",
    "    space[\"epoch\"] = number_of_epochs_it_ran\n",
    "    space[\"val_loss\"] = val_loss\n",
    "    space[\"train_loss\"] = train_loss\n",
    "    df_space = pd.DataFrame(space, index = [0], dtype = object)\n",
    "    filename = dir + \"/grid_search.csv\"\n",
    "    df_space.to_csv(filename, index = False, header = (not os.path.exists(filename)), mode = \"a\")\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    K.clear_session()\n",
    "\n",
    "    # Plot result of the training and validation.\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.title(\"model loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"val\"], loc = \"upper left\")\n",
    "    plt.show()\n",
    "    #except:\n",
    "    #    val_loss = np.inf     \n",
    "    #    clear_output(wait = True)\n",
    "    #    K.clear_session()\n",
    "\n",
    "    return {\"loss\": val_loss, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:36<00:00, 18.14s/trial, best loss: 0.009393044747412205]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn = hyperparameters,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 2,\n",
    "            trials = trials)\n",
    "\n",
    "# Save the trials into a file.\n",
    "pickle.dump(trials, open(dir + \"/hyp_trials.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
